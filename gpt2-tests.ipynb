{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CATS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88358352261946e98eebc5a6f625b6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cfba6e774ae54e83aaed2397c7f5ff28",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f27344f30864daeaeb6239092d6d559",
              "IPY_MODEL_31f48f5e233a484080e34457d7ccf358"
            ]
          }
        },
        "cfba6e774ae54e83aaed2397c7f5ff28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f27344f30864daeaeb6239092d6d559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3338e41eff414b11b47173b58a7630f4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ec213fa07c84a9a9cc56a261984166e"
          }
        },
        "31f48f5e233a484080e34457d7ccf358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6900e000e9742629ffdbb7916bfa02c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.48MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdd9c143bd0e4ec3a646d7505cca5185"
          }
        },
        "3338e41eff414b11b47173b58a7630f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ec213fa07c84a9a9cc56a261984166e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6900e000e9742629ffdbb7916bfa02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdd9c143bd0e4ec3a646d7505cca5185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8fda69fe32e455599695667c68d4927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29b515992c5d4514bec8f3f4bf2c70d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d5d28d1cf0c489faf7449763ea29607",
              "IPY_MODEL_124695dbec24479c82ce3664373042be"
            ]
          }
        },
        "29b515992c5d4514bec8f3f4bf2c70d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d5d28d1cf0c489faf7449763ea29607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9781652fb7004b2cbdefeb700b4a30d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_307e9d967a544aee9d59a0bea525202a"
          }
        },
        "124695dbec24479c82ce3664373042be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd9625509934463d9e67bec0fbcae31c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 4.19MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd8896a4641649398c829d94da870222"
          }
        },
        "9781652fb7004b2cbdefeb700b4a30d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "307e9d967a544aee9d59a0bea525202a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd9625509934463d9e67bec0fbcae31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd8896a4641649398c829d94da870222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c6ed690e42a4acf8a8418a7e3dc33f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cf05c187fa242d7ae894e233c1efe75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e6a890a7eea42a681b9903a4c217320",
              "IPY_MODEL_88f4991f182f48538b8696add954f2d4"
            ]
          }
        },
        "0cf05c187fa242d7ae894e233c1efe75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e6a890a7eea42a681b9903a4c217320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_44cbe0289275412996d286666db17479",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7d4bdf0b27048c989a0d9cf177e75ef"
          }
        },
        "88f4991f182f48538b8696add954f2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e873de9546f84724921cd1263eebbc4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 718/718 [00:00&lt;00:00, 3.64kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9570bcea9144f33b83c52bb98a3b112"
          }
        },
        "44cbe0289275412996d286666db17479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7d4bdf0b27048c989a0d9cf177e75ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e873de9546f84724921cd1263eebbc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9570bcea9144f33b83c52bb98a3b112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10a401edd78e442bbb952c11039a26f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1785550c53774fddb64161b2ae6ce0d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d864fa6c88cb4bc69b317e19771e10f3",
              "IPY_MODEL_3ce95af739b8480e9aaa680a1ccba3fb"
            ]
          }
        },
        "1785550c53774fddb64161b2ae6ce0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d864fa6c88cb4bc69b317e19771e10f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b98876b3a0834581891ab91bc27467c1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1520013706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1520013706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13ef564a95e3425199aae1f03868071c"
          }
        },
        "3ce95af739b8480e9aaa680a1ccba3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42e0e96b882a4055a39807583b2ad9e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.52G/1.52G [00:37&lt;00:00, 40.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79f96fb9d61941c7a8b4119f1f40d356"
          }
        },
        "b98876b3a0834581891ab91bc27467c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13ef564a95e3425199aae1f03868071c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42e0e96b882a4055a39807583b2ad9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79f96fb9d61941c7a8b4119f1f40d356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f029da301c4e41a588b80e35126bbb75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7e93dfe31704993909015baa1447d0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c1af992c0844c8bbfbe120005ea8a73",
              "IPY_MODEL_14f0c48516a445ca96cbfedd9256e1a0"
            ]
          }
        },
        "e7e93dfe31704993909015baa1447d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c1af992c0844c8bbfbe120005ea8a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c66e4ef3b7d745338b253a951bf18118",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1969,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1969,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57285c20f2f947c6b9a9ab6e57bce27c"
          }
        },
        "14f0c48516a445ca96cbfedd9256e1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_074ea1364a354dff8b95384be0e4cc84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.39k/? [00:00&lt;00:00, 44.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db728b653f3146a39ccebd7250f23699"
          }
        },
        "c66e4ef3b7d745338b253a951bf18118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57285c20f2f947c6b9a9ab6e57bce27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "074ea1364a354dff8b95384be0e4cc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db728b653f3146a39ccebd7250f23699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15fcb3d139214b48b4c452ff09962f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_932d353d42a54fcd85623cf453b27bf0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d3fc1c2db0740f4924d366f9778f907",
              "IPY_MODEL_ff680f6c8e504cca802be1a1ec9d0da3"
            ]
          }
        },
        "932d353d42a54fcd85623cf453b27bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d3fc1c2db0740f4924d366f9778f907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e116d6b9133e4f4ba8473a1c6a09b585",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1124,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1124,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baece36a1ebf42d7855e697a860c6076"
          }
        },
        "ff680f6c8e504cca802be1a1ec9d0da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e26586ebdd50465e95cee8aeee897830",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.83k/? [00:00&lt;00:00, 6.69kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6139d544fa34a099abff278c1a59a41"
          }
        },
        "e116d6b9133e4f4ba8473a1c6a09b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baece36a1ebf42d7855e697a860c6076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e26586ebdd50465e95cee8aeee897830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6139d544fa34a099abff278c1a59a41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a810f99593a4c9780b5ea5efaa9c847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bbe12fb065834116acb638a356d93e7e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_737ea6d51a57471d8ffa9340cf5fccdb",
              "IPY_MODEL_ad828970b4674c579fc76a3a9b7d54b2"
            ]
          }
        },
        "bbe12fb065834116acb638a356d93e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "737ea6d51a57471d8ffa9340cf5fccdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_035a25937af04423b7cdd9093a99dff8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4721645,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4721645,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_105e3c549f8f4896b84349bdde95c325"
          }
        },
        "ad828970b4674c579fc76a3a9b7d54b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63fcffa151e244a9a02e5ba3130a4ac8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.72M/4.72M [00:00&lt;00:00, 9.94MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a8a1d9e7b32412e906e4ae1b4304f5d"
          }
        },
        "035a25937af04423b7cdd9093a99dff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "105e3c549f8f4896b84349bdde95c325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63fcffa151e244a9a02e5ba3130a4ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a8a1d9e7b32412e906e4ae1b4304f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a29c08dcef7a4b00bb3aa43bf9516df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fdad50ba37c4062b5e6c3aaca522987",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_30152f8d16bc4b218b894ae113a9b5bc",
              "IPY_MODEL_90d3a18aad544aa399773cb50e0aa438"
            ]
          }
        },
        "4fdad50ba37c4062b5e6c3aaca522987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30152f8d16bc4b218b894ae113a9b5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3eb54344a344decbaa08b196e98c9a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9edf66a966064fd48f4efdd2820aefc1"
          }
        },
        "90d3a18aad544aa399773cb50e0aa438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b65ca9df0f7449f8e54831f92149edc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4358/0 [00:01&lt;00:00,  1.35s/ examples]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72eada6a414049b9a3931c394724680f"
          }
        },
        "f3eb54344a344decbaa08b196e98c9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9edf66a966064fd48f4efdd2820aefc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b65ca9df0f7449f8e54831f92149edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72eada6a414049b9a3931c394724680f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c016437fa2c450d9810065268d1c435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a1ada64bc9843dfa13698fda6846e8d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4af955f149be4714a3acb961c33021e1",
              "IPY_MODEL_365f3d01540b4c7e8138046f796a511b"
            ]
          }
        },
        "7a1ada64bc9843dfa13698fda6846e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4af955f149be4714a3acb961c33021e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5636947fd3134c32a80e7153ca556b07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c0000fe78a441ab8d70eabf93e2bebf"
          }
        },
        "365f3d01540b4c7e8138046f796a511b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d0bfed284f542bdb8c0c5863abe4a04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 36718/0 [00:00&lt;00:00, 75589.26 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a52b6d26fcb44789abbe561a10161531"
          }
        },
        "5636947fd3134c32a80e7153ca556b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c0000fe78a441ab8d70eabf93e2bebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d0bfed284f542bdb8c0c5863abe4a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a52b6d26fcb44789abbe561a10161531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c749ddeefa154ebf9360cc45eb17d976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c607b2b83e5c4e52a2308487f2093eef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7354295b54d14ff185c337c34979ebe5",
              "IPY_MODEL_c51a306747eb410eb4fdafa7b998314d"
            ]
          }
        },
        "c607b2b83e5c4e52a2308487f2093eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7354295b54d14ff185c337c34979ebe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26719ef6ceff4679991a0d304998c22a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b62db8154e14a769aeeaaf2b5974a0c"
          }
        },
        "c51a306747eb410eb4fdafa7b998314d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_893b1e9d3e1847de95d771649b4a45ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3760/0 [00:00&lt;00:00, 48286.71 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e4655de7757434586ea35ca24cff6ca"
          }
        },
        "26719ef6ceff4679991a0d304998c22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b62db8154e14a769aeeaaf2b5974a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "893b1e9d3e1847de95d771649b4a45ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e4655de7757434586ea35ca24cff6ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oetReg4UQujz"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2pqapUGoNJr"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9UdyaAuKpfg",
        "outputId": "45fa2477-7973-4dd4-e8cd-d1bd3597adc9"
      },
      "source": [
        "!git clone https://github.com/XuhuiZhou/CATS.git\r\n",
        "import sys; sys.path.append('./CATS')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CATS'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 77 (delta 33), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (77/77), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ8nIPg4zSNs"
      },
      "source": [
        "import torch\r\n",
        "from scipy.special import softmax\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import pickle\r\n",
        "\r\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\r\n",
        "\r\n",
        "device = 'cpu'\r\n",
        "if torch.cuda.is_available():\r\n",
        "    device = 'cuda'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4obLRS4VyrT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "88358352261946e98eebc5a6f625b6dc",
            "cfba6e774ae54e83aaed2397c7f5ff28",
            "4f27344f30864daeaeb6239092d6d559",
            "31f48f5e233a484080e34457d7ccf358",
            "3338e41eff414b11b47173b58a7630f4",
            "4ec213fa07c84a9a9cc56a261984166e",
            "f6900e000e9742629ffdbb7916bfa02c",
            "bdd9c143bd0e4ec3a646d7505cca5185",
            "d8fda69fe32e455599695667c68d4927",
            "29b515992c5d4514bec8f3f4bf2c70d6",
            "4d5d28d1cf0c489faf7449763ea29607",
            "124695dbec24479c82ce3664373042be",
            "9781652fb7004b2cbdefeb700b4a30d1",
            "307e9d967a544aee9d59a0bea525202a",
            "cd9625509934463d9e67bec0fbcae31c",
            "fd8896a4641649398c829d94da870222",
            "7c6ed690e42a4acf8a8418a7e3dc33f1",
            "0cf05c187fa242d7ae894e233c1efe75",
            "9e6a890a7eea42a681b9903a4c217320",
            "88f4991f182f48538b8696add954f2d4",
            "44cbe0289275412996d286666db17479",
            "c7d4bdf0b27048c989a0d9cf177e75ef",
            "e873de9546f84724921cd1263eebbc4b",
            "f9570bcea9144f33b83c52bb98a3b112",
            "10a401edd78e442bbb952c11039a26f4",
            "1785550c53774fddb64161b2ae6ce0d6",
            "d864fa6c88cb4bc69b317e19771e10f3",
            "3ce95af739b8480e9aaa680a1ccba3fb",
            "b98876b3a0834581891ab91bc27467c1",
            "13ef564a95e3425199aae1f03868071c",
            "42e0e96b882a4055a39807583b2ad9e8",
            "79f96fb9d61941c7a8b4119f1f40d356"
          ]
        },
        "outputId": "39f167cc-de24-443c-997f-89507fb7fcf9"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\r\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\r\n",
        "model=model.to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88358352261946e98eebc5a6f625b6dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8fda69fe32e455599695667c68d4927",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c6ed690e42a4acf8a8418a7e3dc33f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=718.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10a401edd78e442bbb952c11039a26f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1520013706.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "f029da301c4e41a588b80e35126bbb75",
            "e7e93dfe31704993909015baa1447d0b",
            "3c1af992c0844c8bbfbe120005ea8a73",
            "14f0c48516a445ca96cbfedd9256e1a0",
            "c66e4ef3b7d745338b253a951bf18118",
            "57285c20f2f947c6b9a9ab6e57bce27c",
            "074ea1364a354dff8b95384be0e4cc84",
            "db728b653f3146a39ccebd7250f23699",
            "15fcb3d139214b48b4c452ff09962f2f",
            "932d353d42a54fcd85623cf453b27bf0",
            "8d3fc1c2db0740f4924d366f9778f907",
            "ff680f6c8e504cca802be1a1ec9d0da3",
            "e116d6b9133e4f4ba8473a1c6a09b585",
            "baece36a1ebf42d7855e697a860c6076",
            "e26586ebdd50465e95cee8aeee897830",
            "b6139d544fa34a099abff278c1a59a41",
            "9a810f99593a4c9780b5ea5efaa9c847",
            "bbe12fb065834116acb638a356d93e7e",
            "737ea6d51a57471d8ffa9340cf5fccdb",
            "ad828970b4674c579fc76a3a9b7d54b2",
            "035a25937af04423b7cdd9093a99dff8",
            "105e3c549f8f4896b84349bdde95c325",
            "63fcffa151e244a9a02e5ba3130a4ac8",
            "4a8a1d9e7b32412e906e4ae1b4304f5d",
            "a29c08dcef7a4b00bb3aa43bf9516df6",
            "4fdad50ba37c4062b5e6c3aaca522987",
            "30152f8d16bc4b218b894ae113a9b5bc",
            "90d3a18aad544aa399773cb50e0aa438",
            "f3eb54344a344decbaa08b196e98c9a7",
            "9edf66a966064fd48f4efdd2820aefc1",
            "6b65ca9df0f7449f8e54831f92149edc",
            "72eada6a414049b9a3931c394724680f",
            "9c016437fa2c450d9810065268d1c435",
            "7a1ada64bc9843dfa13698fda6846e8d",
            "4af955f149be4714a3acb961c33021e1",
            "365f3d01540b4c7e8138046f796a511b",
            "5636947fd3134c32a80e7153ca556b07",
            "3c0000fe78a441ab8d70eabf93e2bebf",
            "6d0bfed284f542bdb8c0c5863abe4a04",
            "a52b6d26fcb44789abbe561a10161531",
            "c749ddeefa154ebf9360cc45eb17d976",
            "c607b2b83e5c4e52a2308487f2093eef",
            "7354295b54d14ff185c337c34979ebe5",
            "c51a306747eb410eb4fdafa7b998314d",
            "26719ef6ceff4679991a0d304998c22a",
            "2b62db8154e14a769aeeaaf2b5974a0c",
            "893b1e9d3e1847de95d771649b4a45ed",
            "6e4655de7757434586ea35ca24cff6ca"
          ]
        },
        "id": "fZ0IxhOtoBA7",
        "outputId": "5c430d63-8fab-416b-faae-e5ed431e0521"
      },
      "source": [
        "from datasets import load_dataset\r\n",
        "dataset = load_dataset(\"wikitext\", 'wikitext-2-raw-v1')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f029da301c4e41a588b80e35126bbb75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1969.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15fcb3d139214b48b4c452ff09962f2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1124.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset wikitext/wikitext-2-raw-v1 (download: 4.50 MiB, generated: 12.91 MiB, post-processed: Unknown size, total: 17.41 MiB) to /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a810f99593a4c9780b5ea5efaa9c847",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4721645.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a29c08dcef7a4b00bb3aa43bf9516df6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c016437fa2c450d9810065268d1c435",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c749ddeefa154ebf9360cc45eb17d976",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset wikitext downloaded and prepared to /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jABd6xtTim8z"
      },
      "source": [
        "!python run_clm.py \\\r\n",
        "    --model_name_or_path gpt2 \\\r\n",
        "    --block_size 100\\\r\n",
        "    --dataset_name wikitext \\\r\n",
        "    --dataset_config_name wikitext-2-raw-v1 \\\r\n",
        "    --do_train \\\r\n",
        "    --do_eval \\\r\n",
        "    --output_dir /tmp/test-clm\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHylJrIV3m8"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz5ySNMcAVQN"
      },
      "source": [
        " unigram_freq = pickle.load(open('gpt-openwebtext.pickle', \"rb\"))\r\n",
        " unigram_total = sum(unigram_freq.values()) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z_AKYaBXDe2"
      },
      "source": [
        "def predict(text, model, tokenizer):\r\n",
        "    text = text\r\n",
        "    tokenized_text = tokenizer.tokenize(text)\r\n",
        "    sentence_score = 0\r\n",
        "    tokens_tensor = torch.tensor([[50256] + tokenizer.convert_tokens_to_ids(tokenized_text)], device=device)\r\n",
        "    length = len(tokenized_text)\r\n",
        "\r\n",
        "    #unigram logprob\r\n",
        "    uni_lp = 0.0\r\n",
        "    for w in tokenized_text:\r\n",
        "      uni_lp += math.log(float(unigram_freq[w])/unigram_total)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        outputs = model(tokens_tensor, labels= tokens_tensor)\r\n",
        "    loss, logits  = outputs[:2]\r\n",
        "    sentence_score = -loss\r\n",
        "\r\n",
        "\r\n",
        "    lp = float(loss.item()) * -1.0 * length\r\n",
        "    penalty = ((5+length)**0.8 / (5+1)**0.8)*lp\r\n",
        "\r\n",
        "    div_lp = -lp / uni_lp\r\n",
        "    slor = (lp - uni_lp) / length\r\n",
        "    pen_slor = (lp - uni_lp) / penalty\r\n",
        "\r\n",
        "    return sentence_score, lp, penalty, div_lp, slor, pen_slor"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUSOrKDsVoE2"
      },
      "source": [
        "def show_results():\r\n",
        "    with open(\"CATS/commonsense_ability_test/{}.txt\".format(test), \"r\") as f:\r\n",
        "        file = f.readlines()\r\n",
        "    num = len(file)\r\n",
        "    count = 0\r\n",
        "    curr = 0\r\n",
        "    count_slor = 0\r\n",
        "    count_pen_slor = 0\r\n",
        "\r\n",
        "    for line in file:\r\n",
        "        if curr < 20:\r\n",
        "          print(line)\r\n",
        "        line = line.strip().split(\"\\001\")\r\n",
        "        label = int(line[0])\r\n",
        "        score_list = []\r\n",
        "        lp_list = []\r\n",
        "        div_lp_list = []\r\n",
        "        penalty_list = []\r\n",
        "        slors_list = []\r\n",
        "        pen_slor_list = []\r\n",
        "        for sentence in line[1:]:\r\n",
        "            score, lp, penalty, div_lp, slor, pen_slor = predict(sentence, model=model, tokenizer=tokenizer)\r\n",
        "            score_list.append(score)\r\n",
        "            lp_list.append(lp)\r\n",
        "            div_lp_list.append(div_lp)\r\n",
        "            penalty_list.append(penalty)\r\n",
        "            slors_list.append(slor)\r\n",
        "            pen_slor_list.append(pen_slor)\r\n",
        "\r\n",
        "        ppl_list = [math.exp(-element) for element in score_list]\r\n",
        "        if curr < 20:\r\n",
        "            print('scores:', [element.item() for element in score_list])\r\n",
        "            print('ppl:', ppl_list)\r\n",
        "            print('lp:', lp_list)\r\n",
        "            print('div_lp:', div_lp_list)\r\n",
        "            print('penalty:', penalty_list)\r\n",
        "            print('slor:', slors_list)\r\n",
        "            print('pen_slor:',  pen_slor_list, '\\n')\r\n",
        "\r\n",
        "   \r\n",
        "        predict_label = ppl_list.index(min(ppl_list))\r\n",
        "        if predict_label==label:\r\n",
        "            count += 1\r\n",
        "        curr += 1\r\n",
        "\r\n",
        "        predict_label_slore = slors_list.index(max(slors_list))\r\n",
        "        if predict_label_slore==label:\r\n",
        "            count_slor += 1\r\n",
        "\r\n",
        "        predict_label_pen_slore = pen_slor_list.index(min(pen_slor_list))\r\n",
        "        if predict_label_pen_slore==label:\r\n",
        "            count_pen_slor += 1\r\n",
        "        if curr <= 20:\r\n",
        "            print('predicted label ppl:', predict_label, '  correct label:', label)\r\n",
        "            print('correct answers:', count, '  total number of examples:', curr, '  percentage of correct answers:', count/curr, '\\n')\r\n",
        "            print('predicted label slor:', predict_label_slore, '  correct label:', label)\r\n",
        "            print('correct answers:', count_slor, '  total number of examples:', curr, '  percentage of correct answers:', count_slor/curr, '\\n')\r\n",
        "            print('predicted label pen slor:', predict_label_pen_slore, '  correct label:', label)\r\n",
        "            print('correct answers:', count_pen_slor, '  total number of examples:', curr, '  percentage of correct answers:', count_pen_slor/curr, '\\n')\r\n",
        "\r\n",
        "\r\n",
        "    print (' percentage of correct answers ppl:', count/num)\r\n",
        "    print (' percentage of correct answers slor:', count_slor/num)\r\n",
        "    print (' percentage of correct answers pen_slor:', count_pen_slor/num)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjbhW0ptXNRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d79091c-c048-4812-e4f3-9237a2a8feb3"
      },
      "source": [
        "test = 'smr'\r\n",
        "show_results()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\u0001\" he put an elephant into the fridge \" is against common sense because elephants are usually gray while fridges are usually white . \u0001\" he put an elephant into the fridge \" is against common sense because an elephant is much bigger than a fridge . \u0001\" he put an elephant into the fridge \" is against common sense because an elephant cannot eat a fridge . \n",
            "\n",
            "scores: [-4.643041133880615, -4.1690897941589355, -4.5417962074279785]\n",
            "ppl: [103.85971910731682, 64.65657452431266, 93.85923946129311]\n",
            "lp: [-120.719069480896, -100.05815505981445, -95.37772035598755]\n",
            "div_lp: [-0.5288825011342226, -0.5140723453421597, -0.5387877363199289]\n",
            "penalty: [-449.10121906764556, -352.8985621036672, -308.2510865599166]\n",
            "slor: [4.135924182467182, 3.9408383743832665, 3.8878615246683714]\n",
            "pen_slor: [-0.23944274515084202, -0.26800936909857576, -0.26486554493350006] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 1   total number of examples: 1   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 0   total number of examples: 1   percentage of correct answers: 0.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 1   total number of examples: 1   percentage of correct answers: 1.0 \n",
            "\n",
            "0\u0001\" my sister eats a stone after breakfast every day \" is against common sense because no one eats stones . \u0001\" my sister eats a stone after breakfast every day \" is against common sense because stone is usually in round-shapes . \u0001\" my sister eats a stone after breakfast every day \" is against common sense because stone is too large for a girl's mouth . \n",
            "\n",
            "scores: [-5.227263927459717, -5.584451675415039, -4.8683762550354]\n",
            "ppl: [186.28242339665061, 266.2542489556145, 130.1094806695757]\n",
            "lp: [-114.99980640411377, -145.19574356079102, -126.57778263092041]\n",
            "div_lp: [-0.5985355861955794, -0.6533314244330414, -0.5820585170817326]\n",
            "penalty: [-383.0602786631692, -540.1597752284175, -470.89690743036937]\n",
            "slor: [3.506158191491184, 2.9632034144364954, 3.4956904361350736]\n",
            "pen_slor: [-0.20136642849527206, -0.1426305554551328, -0.19301029568335262] \n",
            "\n",
            "predicted label ppl: 2   correct label: 0\n",
            "correct answers: 1   total number of examples: 2   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 2   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 2   total number of examples: 2   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001\" money can be used for buying stars \" is against common sense because stars can be only seen in cloudless dark night . \u0001\" money can be used for buying stars \" is against common sense because no one can get stars and sell them now . \u0001\" money can be used for buying stars \" is against common sense because stars are too expensive for normal people . \n",
            "\n",
            "scores: [-5.8326544761657715, -5.710509777069092, -5.630352020263672]\n",
            "ppl: [341.26335325998053, 302.02499446190785, 278.7602296128539]\n",
            "lp: [-151.64901638031006, -142.7627444267273, -123.86774444580078]\n",
            "div_lp: [-0.7199367585168157, -0.7332969643596741, -0.6982902276857131]\n",
            "penalty: [-564.1673549975835, -517.3576694565411, -412.5990659327696]\n",
            "slor: [2.268966127541098, 2.0769352208187626, 2.432702275833085]\n",
            "pen_slor: [-0.10456670134045815, -0.10036263804692803, -0.12971296953214267] \n",
            "\n",
            "predicted label ppl: 2   correct label: 1\n",
            "correct answers: 1   total number of examples: 3   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label slor: 2   correct label: 1\n",
            "correct answers: 1   total number of examples: 3   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 1\n",
            "correct answers: 2   total number of examples: 3   percentage of correct answers: 0.6666666666666666 \n",
            "\n",
            "1\u0001\" USA is located in the northeastern part of New York \" is against common sense because USA is a nation while New York is its ally . \u0001\" USA is located in the northeastern part of New York \" is against common sense because USA is a nation while New York is its city . \u0001\" USA is located in the northeastern part of New York \" is against common sense because New York is not the capital of USA . \n",
            "\n",
            "scores: [-4.407557964324951, -4.375586032867432, -3.9214107990264893]\n",
            "ppl: [82.06880364834079, 79.48640755307922, 50.47159985744939]\n",
            "lp: [-127.81918096542358, -126.89199495315552, -101.95668077468872]\n",
            "div_lp: [-0.561899128753452, -0.5651054263281979, -0.5136046959429997]\n",
            "penalty: [-511.98609209499966, -508.2722023682716, -379.3010484996296]\n",
            "slor: [3.436479761988881, 3.3673692264689206, 3.713665028749218]\n",
            "pen_slor: [-0.19464964895801487, -0.19212875918176445, -0.2545610963360518] \n",
            "\n",
            "predicted label ppl: 2   correct label: 1\n",
            "correct answers: 1   total number of examples: 4   percentage of correct answers: 0.25 \n",
            "\n",
            "predicted label slor: 2   correct label: 1\n",
            "correct answers: 1   total number of examples: 4   percentage of correct answers: 0.25 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 1\n",
            "correct answers: 2   total number of examples: 4   percentage of correct answers: 0.5 \n",
            "\n",
            "0\u0001\" a man can better see stars and the moon in daytime \" is against common sense because the sun is much brighter than the moon and stars in the day time . \u0001\" a man can better see stars and the moon in daytime \" is against common sense because the moon is much closer to the earth than the sun . \u0001\" a man can better see stars and the moon in daytime \" is against common sense because the sun moves faster than the moon and stars . \n",
            "\n",
            "scores: [-4.189395904541016, -3.9835262298583984, -4.459975242614746]\n",
            "ppl: [65.98291893666806, 53.70608070629787, 86.48536791825214]\n",
            "lp: [-142.43946075439453, -123.48931312561035, -124.87930679321289]\n",
            "div_lp: [-0.5555764871231151, -0.5287157695551774, -0.5661649728211631]\n",
            "penalty: [-636.7383477665417, -517.7860853439099, -488.40559551496546]\n",
            "slor: [3.351232616717211, 3.5508172855806155, 3.4175436020975667]\n",
            "pen_slor: [-0.17894620194944133, -0.21258843945156966, -0.19592572594881286] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 1   total number of examples: 5   percentage of correct answers: 0.2 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 1   total number of examples: 5   percentage of correct answers: 0.2 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 2   total number of examples: 5   percentage of correct answers: 0.4 \n",
            "\n",
            "1\u0001\" he was sent to a restaurant for treatment after a car crash \" is against common sense because a restaurant is usually too noisy for a patient . \u0001\" he was sent to a restaurant for treatment after a car crash \" is against common sense because a restaurant does not have doctors or medical equipment . \u0001\" he was sent to a restaurant for treatment after a car crash \" is against common sense because there are different types of restaurants in the city . \n",
            "\n",
            "scores: [-4.5779523849487305, -4.426135540008545, -4.1274871826171875]\n",
            "ppl: [97.31492655193942, 83.60769321909478, 62.021877308373675]\n",
            "lp: [-137.3385715484619, -132.78406620025635, -119.69712829589844]\n",
            "div_lp: [-0.5924996232541153, -0.5704921975474231, -0.5514247422663697]\n",
            "penalty: [-563.0227726657365, -544.3514686004924, -479.45280581784203]\n",
            "slor: [3.1485544435379893, 3.3323150734034215, 3.357645177699308]\n",
            "pen_slor: [-0.16776698544344326, -0.1836487232396386, -0.20308924876805134] \n",
            "\n",
            "predicted label ppl: 2   correct label: 1\n",
            "correct answers: 1   total number of examples: 6   percentage of correct answers: 0.16666666666666666 \n",
            "\n",
            "predicted label slor: 2   correct label: 1\n",
            "correct answers: 1   total number of examples: 6   percentage of correct answers: 0.16666666666666666 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 1\n",
            "correct answers: 2   total number of examples: 6   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "2\u0001\" his mother became angry after he got good grades in the math exam \" is against common sense because his mother seldom used math in her daily time . \u0001\" his mother became angry after he got good grades in the math exam \" is against common sense because his mother wanted to take the exam herself . \u0001\" his mother became angry after he got good grades in the math exam \" is against common sense because parents are always happy to see their children get good grades . \n",
            "\n",
            "scores: [-4.693053245544434, -4.43942403793335, -4.048527717590332]\n",
            "ppl: [109.1860431918953, 84.72612858181546, 57.31301395636919]\n",
            "lp: [-145.48465061187744, -133.1827211380005, -129.55288696289062]\n",
            "div_lp: [-0.5594556492803796, -0.5414374714367797, -0.4882347510665052]\n",
            "penalty: [-610.0117152755292, -545.9857640926832, -555.2486025840301]\n",
            "slor: [3.6955531642416615, 3.7599051037175237, 4.243646710277993]\n",
            "pen_slor: [-0.18780319332022374, -0.20659357904499862, -0.2445691787370948] \n",
            "\n",
            "predicted label ppl: 2   correct label: 2\n",
            "correct answers: 2   total number of examples: 7   percentage of correct answers: 0.2857142857142857 \n",
            "\n",
            "predicted label slor: 2   correct label: 2\n",
            "correct answers: 2   total number of examples: 7   percentage of correct answers: 0.2857142857142857 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 2\n",
            "correct answers: 3   total number of examples: 7   percentage of correct answers: 0.42857142857142855 \n",
            "\n",
            "1\u0001\" cans are usually made of gold \" is against common sense because gold is too bright to make cans . \u0001\" cans are usually made of gold \" is against common sense because gold is too expensive to make cans . \u0001\" cans are usually made of gold \" is against common sense because gold is too soft to make cans . \n",
            "\n",
            "scores: [-5.039920330047607, -4.764087200164795, -4.838503360748291]\n",
            "ppl: [154.4577088973685, 117.22406632876577, 126.28021430472924]\n",
            "lp: [-110.87824726104736, -104.80991840362549, -101.60857057571411]\n",
            "div_lp: [-0.6135301364508288, -0.5818150126054273, -0.5845531466654631]\n",
            "penalty: [-369.3315112570593, -349.1181229407758, -328.38856041915875]\n",
            "slor: [3.1747052125585316, 3.4242322775859138, 3.438765161967134]\n",
            "pen_slor: [-0.18910792214443828, -0.21578115015149063, -0.21990433622028427] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 3   total number of examples: 8   percentage of correct answers: 0.375 \n",
            "\n",
            "predicted label slor: 2   correct label: 1\n",
            "correct answers: 2   total number of examples: 8   percentage of correct answers: 0.25 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 1\n",
            "correct answers: 3   total number of examples: 8   percentage of correct answers: 0.375 \n",
            "\n",
            "0\u0001\" I put my desktop into my suitcase before departure \" is against common sense because suitcases are not big enough for a desktop . \u0001\" I put my desktop into my suitcase before departure \" is against common sense because I do not need my desktop anymore . \u0001\" I put my desktop into my suitcase before departure \" is against common sense because suitcases can only filled with clothes . \n",
            "\n",
            "scores: [-4.8613433837890625, -4.792866230010986, -5.4432692527771]\n",
            "ppl: [129.19764760473623, 120.64667468328093, 231.19679003660005]\n",
            "lp: [-131.2562713623047, -119.82165575027466, -130.6384620666504]\n",
            "div_lp: [-0.5790612742218169, -0.5741530141219764, -0.6213558557191811]\n",
            "penalty: [-500.8631093883179, -434.22149677994344, -460.75330282869686]\n",
            "slor: [3.5338707329243655, 3.554849643849709, 3.317039679174384]\n",
            "pen_slor: [-0.19050017459956956, -0.20466799031205327, -0.17277999270204467] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 9   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 2   total number of examples: 9   percentage of correct answers: 0.2222222222222222 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 9   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "0\u0001\" I walk to the Moon \" is against common sense because the Moon is to far to walk to . \u0001\" I walk to the Moon \" is against common sense because the Moon's gravity is relatively small . \u0001\" I walk to the Moon \" is against common sense because I don't know where the Moon is . \n",
            "\n",
            "scores: [-4.769894123077393, -4.564909934997559, -3.826754331588745]\n",
            "ppl: [117.90675769512514, 96.053942528368, 45.91327686640982]\n",
            "lp: [-104.93767070770264, -95.86310863494873, -80.36184096336365]\n",
            "div_lp: [-0.6669427689138657, -0.5886923823808087, -0.516222765564234]\n",
            "penalty: [-349.5436613371422, -309.8198120844393, -259.72129237786885]\n",
            "slor: [2.381985086656441, 3.1894114586919664, 3.586235925448998]\n",
            "pen_slor: [-0.14992024660374903, -0.21618256166999733, -0.2899683493213909] \n",
            "\n",
            "predicted label ppl: 2   correct label: 0\n",
            "correct answers: 3   total number of examples: 10   percentage of correct answers: 0.3 \n",
            "\n",
            "predicted label slor: 2   correct label: 0\n",
            "correct answers: 2   total number of examples: 10   percentage of correct answers: 0.2 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 0\n",
            "correct answers: 3   total number of examples: 10   percentage of correct answers: 0.3 \n",
            "\n",
            "2\u0001\" I work 25 hours a day \" is against common sense because I'm too lazy to work . \u0001\" I work 25 hours a day \" is against common sense because I don't like stay up late . \u0001\" I work 25 hours a day \" is against common sense because a day only has 24 hours . \n",
            "\n",
            "scores: [-4.407932758331299, -4.546753406524658, -4.696505546569824]\n",
            "ppl: [82.09956830890137, 94.32567354650662, 109.56363769067646]\n",
            "lp: [-92.56658792495728, -100.02857494354248, -93.93011093139648]\n",
            "div_lp: [-0.5684434729007485, -0.5900303737862717, -0.6111302004407538]\n",
            "penalty: [-299.16579260348055, -333.1916373624644, -294.1953756098718]\n",
            "slor: [3.34645790401154, 3.159211588714115, 2.988445292355584]\n",
            "pen_slor: [-0.23490525227724426, -0.2085966367640304, -0.2031605891942039] \n",
            "\n",
            "predicted label ppl: 0   correct label: 2\n",
            "correct answers: 3   total number of examples: 11   percentage of correct answers: 0.2727272727272727 \n",
            "\n",
            "predicted label slor: 0   correct label: 2\n",
            "correct answers: 2   total number of examples: 11   percentage of correct answers: 0.18181818181818182 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 2\n",
            "correct answers: 3   total number of examples: 11   percentage of correct answers: 0.2727272727272727 \n",
            "\n",
            "0\u0001\" I'm hungry for water \" is against common sense because Water is used to quench thirsty . \u0001\" I'm hungry for water \" is against common sense because Water is necessary for our daily lives . \u0001\" I'm hungry for water \" is against common sense because I'm not that hungry . \n",
            "\n",
            "scores: [-5.040342807769775, -4.658662796020508, -4.516782283782959]\n",
            "ppl: [154.52297762471557, 105.49491956984264, 91.54057199473723]\n",
            "lp: [-105.84719896316528, -97.83191871643066, -81.30208110809326]\n",
            "div_lp: [-0.5959725733926865, -0.5751667168935898, -0.5692415983466028]\n",
            "penalty: [-342.0873760448512, -316.1828059218028, -238.21161361723682]\n",
            "slor: [3.4169974001472965, 3.441011018871664, 3.4179545606469457]\n",
            "pen_slor: [-0.2097620386719127, -0.22854257107888504, -0.25827112774821176] \n",
            "\n",
            "predicted label ppl: 2   correct label: 0\n",
            "correct answers: 3   total number of examples: 12   percentage of correct answers: 0.25 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 2   total number of examples: 12   percentage of correct answers: 0.16666666666666666 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 0\n",
            "correct answers: 3   total number of examples: 12   percentage of correct answers: 0.25 \n",
            "\n",
            "1\u0001\" this basket can hold one gallon of water \" is against common sense because the basket is too small . \u0001\" this basket can hold one gallon of water \" is against common sense because baskets cannot hold water . \u0001\" this basket can hold one gallon of water \" is against common sense because baskets are made of wood . \n",
            "\n",
            "scores: [-4.640676021575928, -5.030020713806152, -4.887674808502197]\n",
            "ppl: [103.61436946179634, 152.9361805532031, 132.64479066067366]\n",
            "lp: [-102.09487247467041, -105.6304349899292, -102.64117097854614]\n",
            "div_lp: [-0.5784057022510833, -0.5874049281680117, -0.5877974284821011]\n",
            "penalty: [-340.0744011933309, -341.38681694124006, -331.7258198437619]\n",
            "slor: [3.382543672688827, 3.5331023936108954, 3.427561991910295]\n",
            "pen_slor: [-0.21882258863950485, -0.2173345500877949, -0.21698281389135515] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 3   total number of examples: 13   percentage of correct answers: 0.23076923076923078 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 3   total number of examples: 13   percentage of correct answers: 0.23076923076923078 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 3   total number of examples: 13   percentage of correct answers: 0.23076923076923078 \n",
            "\n",
            "2\u0001\" this man can jump across a mountain easily \" is against common sense because this man cannot jump very far . \u0001\" this man can jump across a mountain easily \" is against common sense because this man lives in the mountain . \u0001\" this man can jump across a mountain easily \" is against common sense because a mountain is too big for a man to jump across . \n",
            "\n",
            "scores: [-4.925411701202393, -5.019498348236084, -4.156717300415039]\n",
            "ppl: [137.74604018099694, 151.33536709490969, 63.86153988294544]\n",
            "lp: [-113.28446912765503, -115.44846200942993, -112.23136711120605]\n",
            "div_lp: [-0.6016181727270875, -0.6377372259456793, -0.5314999152177704]\n",
            "penalty: [-388.4863810457251, -395.9073609004492, -428.26564337682436]\n",
            "slor: [3.2615279965728456, 2.8512956779285914, 3.6640126402697413]\n",
            "pen_slor: [-0.1930959425636754, -0.16564430740363936, -0.23099761285365936] \n",
            "\n",
            "predicted label ppl: 2   correct label: 2\n",
            "correct answers: 4   total number of examples: 14   percentage of correct answers: 0.2857142857142857 \n",
            "\n",
            "predicted label slor: 2   correct label: 2\n",
            "correct answers: 4   total number of examples: 14   percentage of correct answers: 0.2857142857142857 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 2\n",
            "correct answers: 4   total number of examples: 14   percentage of correct answers: 0.2857142857142857 \n",
            "\n",
            "1\u0001\" I put the rubbish into a mailbox \" is against common sense because I do not want to deliver the rubbish . \u0001\" I put the rubbish into a mailbox \" is against common sense because Rubbish should be thrown into a trash can, rather than a mailbox . \u0001\" I put the rubbish into a mailbox \" is against common sense because a mailbox is not big enough for any rubbish . \n",
            "\n",
            "scores: [-4.715796947479248, -4.329800128936768, -4.43629789352417]\n",
            "ppl: [111.697792986641, 75.92910902071121, 84.46167604242139]\n",
            "lp: [-113.17912673950195, -129.89400386810303, -106.47114944458008]\n",
            "div_lp: [-0.6063896838181346, -0.5215890675591569, -0.54848064033512]\n",
            "penalty: [-399.175370189891, -532.5035886562074, -375.51677344096186]\n",
            "slor: [3.061045359247043, 3.971371038623596, 3.652042090205439]\n",
            "pen_slor: [-0.18404213813838535, -0.22373770561690476, -0.23340904152370856] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 5   total number of examples: 15   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 5   total number of examples: 15   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 1\n",
            "correct answers: 4   total number of examples: 15   percentage of correct answers: 0.26666666666666666 \n",
            "\n",
            "0\u0001\" most children hate candies \" is against common sense because candies are sweet and children love sweet things . \u0001\" most children hate candies \" is against common sense because candies are bitter and children love bitter things . \u0001\" most children hate candies \" is against common sense because children are not allowed to eat candies freely by their parents . \n",
            "\n",
            "scores: [-4.504389762878418, -4.764047622680664, -4.231673240661621]\n",
            "ppl: [90.41315374830022, 117.21942698694824, 68.83230888954508]\n",
            "lp: [-103.60096454620361, -109.57309532165527, -105.79183101654053]\n",
            "div_lp: [-0.5155688158960551, -0.5398640011148347, -0.4902636767659129]\n",
            "penalty: [-355.2787429673877, -375.75896845595497, -383.3788385200792]\n",
            "slor: [4.232348426086364, 4.060485246417421, 4.399749891838006]\n",
            "pen_slor: [-0.27399335233777816, -0.2485400709166244, -0.2869061519424195] \n",
            "\n",
            "predicted label ppl: 2   correct label: 0\n",
            "correct answers: 5   total number of examples: 16   percentage of correct answers: 0.3125 \n",
            "\n",
            "predicted label slor: 2   correct label: 0\n",
            "correct answers: 5   total number of examples: 16   percentage of correct answers: 0.3125 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 0\n",
            "correct answers: 4   total number of examples: 16   percentage of correct answers: 0.25 \n",
            "\n",
            "0\u0001\" most people become wiser after drinking a lot alcohol \" is against common sense because the alcohol makes drinker stupid . \u0001\" most people become wiser after drinking a lot alcohol \" is against common sense because most people do not need alcohol to become wise . \u0001\" most people become wiser after drinking a lot alcohol \" is against common sense because most drinkers do not drink enough alcohol . \n",
            "\n",
            "scores: [-5.193498611450195, -4.3546833992004395, -4.619597911834717]\n",
            "ppl: [180.0975433209736, 77.8421765397875, 101.45323078379829]\n",
            "lp: [-124.64396667480469, -117.57645177841187, -110.8703498840332]\n",
            "div_lp: [-0.6124631710947332, -0.5296644123839637, -0.533418351217573]\n",
            "penalty: [-439.6111100403649, -448.6620457625878, -391.03246537592474]\n",
            "slor: [3.286192668871518, 3.8669061533248454, 4.040767636688482]\n",
            "pen_slor: [-0.17940543869711287, -0.23270625881070878, -0.24800606565312155] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 5   total number of examples: 17   percentage of correct answers: 0.29411764705882354 \n",
            "\n",
            "predicted label slor: 2   correct label: 0\n",
            "correct answers: 5   total number of examples: 17   percentage of correct answers: 0.29411764705882354 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 0\n",
            "correct answers: 4   total number of examples: 17   percentage of correct answers: 0.23529411764705882 \n",
            "\n",
            "1\u0001\" a salad usually contains grass \" is against common sense because grass cannot be bought everywhere . \u0001\" a salad usually contains grass \" is against common sense because human do not eat grass . \u0001\" a salad usually contains grass \" is against common sense because only some salads contain grass . \n",
            "\n",
            "scores: [-6.044435501098633, -5.7557549476623535, -5.638559818267822]\n",
            "ppl: [421.75960743632686, 316.00402399346035, 281.05765276397483]\n",
            "lp: [-114.84427452087402, -109.35934400558472, -101.4940767288208]\n",
            "div_lp: [-0.686032512769444, -0.6692183179444845, -0.6222149350066897]\n",
            "penalty: [-348.14273892031355, -331.5155388239487, -297.3732955005174]\n",
            "slor: [2.7662773858137624, 2.8449584418653773, 3.423517449625466]\n",
            "pen_slor: [-0.15097046255642801, -0.16305181526995527, -0.20722544702455023] \n",
            "\n",
            "predicted label ppl: 2   correct label: 1\n",
            "correct answers: 5   total number of examples: 18   percentage of correct answers: 0.2777777777777778 \n",
            "\n",
            "predicted label slor: 2   correct label: 1\n",
            "correct answers: 5   total number of examples: 18   percentage of correct answers: 0.2777777777777778 \n",
            "\n",
            "predicted label pen slor: 2   correct label: 1\n",
            "correct answers: 4   total number of examples: 18   percentage of correct answers: 0.2222222222222222 \n",
            "\n",
            "2\u0001\" computers are everywhere in a forest \" is against common sense because computers can shine while trees cannot . \u0001\" computers are everywhere in a forest \" is against common sense because computers grow more slowly than trees . \u0001\" computers are everywhere in a forest \" is against common sense because computers are not plants . \n",
            "\n",
            "scores: [-5.427098751068115, -4.97934627532959, -5.0464301109313965]\n",
            "ppl: [227.4882869355823, 145.37931253930876, 155.4664745975478]\n",
            "lp: [-113.96907377243042, -104.56627178192139, -90.83574199676514]\n",
            "div_lp: [-0.6436680169087465, -0.5959965393865834, -0.6235633132522744]\n",
            "penalty: [-368.33644894694254, -337.9475497421378, -266.14483147608445]\n",
            "slor: [3.004419684680915, 3.3753100796460194, 3.0464611860422712]\n",
            "pen_slor: [-0.17129125710659032, -0.20974116168811022, -0.20603932469636715] \n",
            "\n",
            "predicted label ppl: 1   correct label: 2\n",
            "correct answers: 5   total number of examples: 19   percentage of correct answers: 0.2631578947368421 \n",
            "\n",
            "predicted label slor: 1   correct label: 2\n",
            "correct answers: 5   total number of examples: 19   percentage of correct answers: 0.2631578947368421 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 2\n",
            "correct answers: 4   total number of examples: 19   percentage of correct answers: 0.21052631578947367 \n",
            "\n",
            "1\u0001\" my family used to watch radio together after dinner \" is against common sense because radios are not big enough for a whole family . \u0001\" my family used to watch radio together after dinner \" is against common sense because radios cannot be watched but only listened to . \u0001\" my family used to watch radio together after dinner \" is against common sense because radios are not interesting as TVs . \n",
            "\n",
            "scores: [-4.710658073425293, -4.888805389404297, -5.439657688140869]\n",
            "ppl: [111.12526443238943, 132.79484113387426, 230.36331386816806]\n",
            "lp: [-127.18776798248291, -127.10894012451172, -125.11212682723999]\n",
            "div_lp: [-0.5839812086373761, -0.5864674114014347, -0.644150804776965]\n",
            "penalty: [-485.3380359405921, -472.8729289397674, -429.04696248590125]\n",
            "slor: [3.3557968120269916, 3.4472168589963537, 3.005038255419012]\n",
            "pen_slor: [-0.18668743682767835, -0.18953852684030809, -0.16109164244906748] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 5   total number of examples: 20   percentage of correct answers: 0.25 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 6   total number of examples: 20   percentage of correct answers: 0.3 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 5   total number of examples: 20   percentage of correct answers: 0.25 \n",
            "\n",
            " percentage of correct answers ppl: 0.39188520534388915\n",
            " percentage of correct answers slor: 0.4458189015338941\n",
            " percentage of correct answers pen_slor: 0.44730331519049976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWV29Vk5gvaR",
        "outputId": "f5cf6da0-50ae-4655-f882-3a7229d59378"
      },
      "source": [
        "test = 'ca'\r\n",
        "show_results()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\u0001The trophy doesn't fit into the brown suitcase because the trophy is too large.\u0001The trophy doesn't fit into the brown suitcase and the trophy is too large.\n",
            "\n",
            "scores: [-3.7938218116760254, -3.8596951961517334]\n",
            "ppl: [44.42586352534108, 47.45088595176637]\n",
            "lp: [-60.701148986816406, -61.755123138427734]\n",
            "div_lp: [-0.4590139699963686, -0.4783520303447394]\n",
            "penalty: [-165.36795173376305, -168.2392902428603]\n",
            "slor: [4.471333629466734, 4.209038605124542]\n",
            "pen_slor: [-0.4326191219121281, -0.4002906668518273] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 1   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 1   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 1   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001The trophy doesn't fit into the brown suitcase and the suitcase is too small.\u0001The trophy doesn't fit into the brown suitcase because the suitcase is too small.\n",
            "\n",
            "scores: [-3.8124687671661377, -3.639209747314453]\n",
            "ppl: [45.26204249232877, 38.06174644015966]\n",
            "lp: [-60.9995002746582, -58.22735595703125]\n",
            "div_lp: [-0.46841751130618514, -0.43659367557692574]\n",
            "penalty: [-166.18074922097773, -158.62860506278523]\n",
            "slor: [4.326571032040013, 4.696251691758183]\n",
            "pen_slor: [-0.41656531720523504, -0.4736852287038047] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 2   total number of examples: 2   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 2   total number of examples: 2   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 2   total number of examples: 2   percentage of correct answers: 1.0 \n",
            "\n",
            "0\u0001Paul tried to call George on the phone, but paul wasn't successful.\u0001Paul tried to call George on the phone, and paul wasn't successful.\n",
            "\n",
            "scores: [-4.1636247634887695, -4.320913314819336]\n",
            "ppl: [64.30418813975608, 75.25733054910685]\n",
            "lp: [-66.61799621582031, -69.13461303710938]\n",
            "div_lp: [-0.529525551447466, -0.5588608519685001]\n",
            "penalty: [-181.48720027046667, -188.3432116636891]\n",
            "slor: [3.6993098052160622, 3.410730974809457]\n",
            "pen_slor: [-0.3261329548047956, -0.2897460180003517] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 3   total number of examples: 3   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 3   total number of examples: 3   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 3   total number of examples: 3   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001Paul tried to call George on the phone, and george wasn't available.\u0001Paul tried to call George on the phone, but george wasn't available.\n",
            "\n",
            "scores: [-3.9186341762542725, -3.699160575866699]\n",
            "ppl: [50.331653642769425, 40.41336616292428]\n",
            "lp: [-62.69814682006836, -59.18656921386719]\n",
            "div_lp: [-0.49394761665589115, -0.45869174584585176]\n",
            "penalty: [-170.80836673106998, -161.2417867604378]\n",
            "slor: [4.014664910770558, 4.365428790234171]\n",
            "pen_slor: [-0.37606260045483286, -0.4331808896878605] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 4   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 4   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 4   percentage of correct answers: 1.0 \n",
            "\n",
            "0\u0001The lawyer asked the witness a question, but the lawyer was reluctant to repeat it.\u0001The lawyer asked the witness a question, and the lawyer was reluctant to repeat it.\n",
            "\n",
            "scores: [-3.539111852645874, -3.542919874191284]\n",
            "ppl: [34.43632107760115, 34.56770532847115]\n",
            "lp: [-60.16490149497986, -60.22963786125183]\n",
            "div_lp: [-0.4865179093573076, -0.4954575667480832]\n",
            "penalty: [-170.12195087243478, -170.3049990724472]\n",
            "slor: [3.7352593155626246, 3.607883972533882]\n",
            "pen_slor: [-0.37325817179335885, -0.3601422616313494] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 5   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 5   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 5   percentage of correct answers: 1.0 \n",
            "\n",
            "0\u0001The lawyer asked the witness a question, but the witness was reluctant to answer it.\u0001The lawyer asked the witness a question, and the witness was reluctant to answer it.\n",
            "\n",
            "scores: [-2.962259292602539, -2.9777109622955322]\n",
            "ppl: [19.341620809759807, 19.642802029874485]\n",
            "lp: [-50.358407974243164, -50.62108635902405]\n",
            "div_lp: [-0.4107301576939706, -0.4200697154219553]\n",
            "penalty: [-142.39316270006788, -143.13591068370204]\n",
            "slor: [4.249919402125005, 4.11090041094868]\n",
            "pen_slor: [-0.5073883356907181, -0.48824440108924355] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 6   total number of examples: 6   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 6   total number of examples: 6   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 6   total number of examples: 6   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001The delivery truck zoomed by the school bus and the delivery truck was going so fast.\u0001The delivery truck zoomed by the school bus because the delivery truck was going so fast.\n",
            "\n",
            "scores: [-3.8400988578796387, -3.63726544380188]\n",
            "ppl: [46.53007407689295, 37.98781474897525]\n",
            "lp: [-69.1217794418335, -65.47077798843384]\n",
            "div_lp: [-0.47829523436180116, -0.4433895604890739]\n",
            "penalty: [-202.5238516962738, -191.82657389379165]\n",
            "slor: [4.188621861036909, 4.566052288329321]\n",
            "pen_slor: [-0.37227809399820705, -0.4284544081751323] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 7   total number of examples: 7   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 7   total number of examples: 7   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 7   total number of examples: 7   percentage of correct answers: 1.0 \n",
            "\n",
            "0\u0001The delivery truck zoomed by the school bus because the school bus was going so slow.\u0001The delivery truck zoomed by the school bus and the school bus was going so slow.\n",
            "\n",
            "scores: [-3.51607608795166, -3.753390312194824]\n",
            "ppl: [33.65212108896746, 42.66548639257325]\n",
            "lp: [-63.28936958312988, -67.56102561950684]\n",
            "div_lp: [-0.4346364524390218, -0.4742064582417557]\n",
            "penalty: [-185.43514074591457, -197.95090987967504]\n",
            "slor: [4.57361834108373, 4.161707103625911]\n",
            "pen_slor: [-0.4439564680586082, -0.3784308337395422] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 8   total number of examples: 8   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 8   total number of examples: 8   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 8   total number of examples: 8   percentage of correct answers: 1.0 \n",
            "\n",
            "0\u0001Frank felt vindicated when his longtime rival Bill revealed that frank was the winner of the competition.\u0001Frank felt vindicated before his longtime rival Bill revealed that frank was the winner of the competition.\n",
            "\n",
            "scores: [-4.54899787902832, -4.901249885559082]\n",
            "ppl: [94.53762269521215, 134.4577314796927]\n",
            "lp: [-86.43095970153809, -93.12374782562256]\n",
            "div_lp: [-0.5241953176076377, -0.5622709203971248]\n",
            "penalty: [-262.0096749580278, -282.29841462966556]\n",
            "slor: [4.1290610929391915, 3.8156332178697627]\n",
            "pen_slor: [-0.2994246711630483, -0.25680991242770895] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 9   total number of examples: 9   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 9   total number of examples: 9   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 9   total number of examples: 9   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001Frank felt crushed before his longtime rival Bill revealed that bill was the winner of the competition.\u0001Frank felt crushed when his longtime rival Bill revealed that bill was the winner of the competition.\n",
            "\n",
            "scores: [-5.564228534698486, -5.117166996002197]\n",
            "ppl: [260.923832361247, 166.8619787257593]\n",
            "lp: [-100.15611362457275, -92.10900592803955]\n",
            "div_lp: [-0.6688305790735871, -0.618137898298543]\n",
            "penalty: [-293.4531209406619, -269.87544023167396]\n",
            "slor: [2.755110784992352, 3.161191296035012]\n",
            "pen_slor: [-0.16899460455862783, -0.21084335528932646] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 10   total number of examples: 10   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 10   total number of examples: 10   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 10   total number of examples: 10   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001The man couldn't lift his son and the man was so weak.\u0001The man couldn't lift his son because the man was so weak.\n",
            "\n",
            "scores: [-3.990429162979126, -3.6818692684173584]\n",
            "ppl: [54.078092699332345, 39.720573133563086]\n",
            "lp: [-55.866008281707764, -51.54616975784302]\n",
            "div_lp: [-0.5307940858717968, -0.4755505658379523]\n",
            "penalty: [-140.4848596301223, -129.62186928383255]\n",
            "slor: [3.5274186601085984, 4.060460428803494]\n",
            "pen_slor: [-0.35152443737739025, -0.4385559806946809] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 11   total number of examples: 11   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 11   total number of examples: 11   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 11   total number of examples: 11   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001The man couldn't lift his son and the son was so heavy.\u0001The man couldn't lift his son because the son was so heavy.\n",
            "\n",
            "scores: [-4.214902400970459, -3.6704792976379395]\n",
            "ppl: [67.68755930843956, 39.27072371538446]\n",
            "lp: [-59.008633613586426, -51.38671016693115]\n",
            "div_lp: [-0.5574114000698864, -0.471417584423409]\n",
            "penalty: [-148.38754128213498, -129.22088022205875]\n",
            "slor: [3.346662361504812, 4.115567338970459]\n",
            "pen_slor: [-0.315749372597147, -0.4458872486131751] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 12   total number of examples: 12   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 12   total number of examples: 12   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 12   total number of examples: 12   percentage of correct answers: 1.0 \n",
            "\n",
            "1\u0001The large ball crashed right through the table and the large ball was made of steel.\u0001The large ball crashed right through the table because the large ball was made of steel.\n",
            "\n",
            "scores: [-4.07098913192749, -4.319828033447266]\n",
            "ppl: [58.61491180815414, 75.17569947450484]\n",
            "lp: [-69.20681524276733, -73.43707656860352]\n",
            "div_lp: [-0.5393322003625769, -0.5586174170590472]\n",
            "penalty: [-195.68881740378353, -207.6502815060976]\n",
            "slor: [3.4772142373330257, 3.413242761569943]\n",
            "pen_slor: [-0.3020747062551287, -0.27943678441382286] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 12   total number of examples: 13   percentage of correct answers: 0.9230769230769231 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 12   total number of examples: 13   percentage of correct answers: 0.9230769230769231 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 12   total number of examples: 13   percentage of correct answers: 0.9230769230769231 \n",
            "\n",
            "0\u0001The large ball crashed right through the table because the table was made of styrofoam.\u0001The large ball crashed right through the table and the table was made of styrofoam.\n",
            "\n",
            "scores: [-3.6463510990142822, -3.5034232139587402]\n",
            "ppl: [38.334531625962576, 33.2290074876325]\n",
            "lp: [-69.28067088127136, -66.56504106521606]\n",
            "div_lp: [-0.4379160838005947, -0.4292784717121829]\n",
            "penalty: [-210.0197211873951, -201.78747098598592]\n",
            "slor: [4.68024669882922, 4.657766887155089]\n",
            "pen_slor: [-0.4234111290834921, -0.43856821448588756] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 12   total number of examples: 14   percentage of correct answers: 0.8571428571428571 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 13   total number of examples: 14   percentage of correct answers: 0.9285714285714286 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 12   total number of examples: 14   percentage of correct answers: 0.8571428571428571 \n",
            "\n",
            "1\u0001John couldn't see the stage with Billy in front of him and john is so short.\u0001John couldn't see the stage with Billy in front of him because john is so short.\n",
            "\n",
            "scores: [-4.7674641609191895, -4.532342910766602]\n",
            "ppl: [117.62059655690642, 92.97614089908457]\n",
            "lp: [-85.81435489654541, -81.58217239379883]\n",
            "div_lp: [-0.6183749859450943, -0.5748594783602154]\n",
            "penalty: [-251.43238245341055, -239.0322690816319]\n",
            "slor: [2.942201121923435, 3.3519193852906772]\n",
            "pen_slor: [-0.21063166040052556, -0.25241173155005003] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 13   total number of examples: 15   percentage of correct answers: 0.8666666666666667 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 14   total number of examples: 15   percentage of correct answers: 0.9333333333333333 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 13   total number of examples: 15   percentage of correct answers: 0.8666666666666667 \n",
            "\n",
            "1\u0001John couldn't see the stage with Billy in front of him and billy is so tall.\u0001John couldn't see the stage with Billy in front of him because billy is so tall.\n",
            "\n",
            "scores: [-4.46117639541626, -4.1802778244018555]\n",
            "ppl: [86.58931247436715, 65.38401596599189]\n",
            "lp: [-84.76235151290894, -79.42527866363525]\n",
            "div_lp: [-0.5855134655105702, -0.5369889475171311]\n",
            "penalty: [-256.95140080898756, -240.77242134035365]\n",
            "slor: [3.158078597337999, 3.6043848650820753]\n",
            "pen_slor: [-0.23352078704574702, -0.2844317137956264] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 14   total number of examples: 16   percentage of correct answers: 0.875 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 15   total number of examples: 16   percentage of correct answers: 0.9375 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 14   total number of examples: 16   percentage of correct answers: 0.875 \n",
            "\n",
            "1\u0001Although they ran at about the same speed, Sue beat Sally and sue had such a good start.\u0001Although they ran at about the same speed, Sue beat Sally because sue had such a good start.\n",
            "\n",
            "scores: [-4.833461284637451, -4.595894813537598]\n",
            "ppl: [125.64510233985678, 99.07675111270832]\n",
            "lp: [-96.66922569274902, -91.91789627075195]\n",
            "div_lp: [-0.6042585448096625, -0.5634894635949943]\n",
            "penalty: [-302.7744658298675, -287.8929850130122]\n",
            "slor: [3.165534056272391, 3.560237839265433]\n",
            "pen_slor: [-0.20910178456403528, -0.24733064191227286] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 15   total number of examples: 17   percentage of correct answers: 0.8823529411764706 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 16   total number of examples: 17   percentage of correct answers: 0.9411764705882353 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 15   total number of examples: 17   percentage of correct answers: 0.8823529411764706 \n",
            "\n",
            "1\u0001Although they ran at about the same speed, Sue beat Sally and sally had such a bad start.\u0001Although they ran at about the same speed, Sue beat Sally because sally had such a bad start.\n",
            "\n",
            "scores: [-4.8361029624938965, -4.648399353027344]\n",
            "ppl: [125.9774550155549, 104.41771584217538]\n",
            "lp: [-101.55816221237183, -97.61638641357422]\n",
            "div_lp: [-0.6022746906185783, -0.5683067575981822]\n",
            "penalty: [-328.22564571838825, -315.4862274515239]\n",
            "slor: [3.193626723684482, 3.530984915906453]\n",
            "pen_slor: [-0.20432943638692908, -0.23503619740557183] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 16   total number of examples: 18   percentage of correct answers: 0.8888888888888888 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 17   total number of examples: 18   percentage of correct answers: 0.9444444444444444 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 16   total number of examples: 18   percentage of correct answers: 0.8888888888888888 \n",
            "\n",
            "1\u0001The sculpture rolled off the shelf and the sculpture wasn't anchored.\u0001The sculpture rolled off the shelf because the sculpture wasn't anchored.\n",
            "\n",
            "scores: [-4.942276477813721, -5.082366466522217]\n",
            "ppl: [140.08879587638722, 161.15497288544998]\n",
            "lp: [-64.24959421157837, -66.07076406478882]\n",
            "div_lp: [-0.5784906415831456, -0.578517965367965]\n",
            "penalty: [-154.72745879959052, -159.11324499618092]\n",
            "slor: [3.601122710612692, 3.7027824325091037]\n",
            "pen_slor: [-0.30256165002102964, -0.30252774760375056] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 16   total number of examples: 19   percentage of correct answers: 0.8421052631578947 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 18   total number of examples: 19   percentage of correct answers: 0.9473684210526315 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 16   total number of examples: 19   percentage of correct answers: 0.8421052631578947 \n",
            "\n",
            "1\u0001The sculpture rolled off the shelf and the shelf wasn't level.\u0001The sculpture rolled off the shelf because the shelf wasn't level.\n",
            "\n",
            "scores: [-5.11824893951416, -4.747281074523926]\n",
            "ppl: [167.04261166073016, 115.27044631604555]\n",
            "lp: [-66.53723621368408, -61.714653968811035]\n",
            "div_lp: [-0.6274060465233501, -0.5651832464366784]\n",
            "penalty: [-160.23661474014642, -148.62275313124678]\n",
            "slor: [3.039544514782228, 3.652262090377368]\n",
            "pen_slor: [-0.24659831185430633, -0.31946257335831585] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 17   total number of examples: 20   percentage of correct answers: 0.85 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 19   total number of examples: 20   percentage of correct answers: 0.95 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 17   total number of examples: 20   percentage of correct answers: 0.85 \n",
            "\n",
            " percentage of correct answers ppl: 0.8633879781420765\n",
            " percentage of correct answers slor: 0.9234972677595629\n",
            " percentage of correct answers pen_slor: 0.912568306010929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd9kq2uFNaIS",
        "outputId": "f75594cf-2df2-41bc-a000-7bd60331f84a"
      },
      "source": [
        "test = 'arct_1'\r\n",
        "show_results()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\u0001They add a lot to the piece and I look forward to reading comments, and since comments sections are a welcome distraction from my work, Comment sections have not failed\u0001They add a lot to the piece and I look forward to reading comments, but since comments sections always distract me from my work, Comment sections have not failed\n",
            "\n",
            "scores: [-4.193867206573486, -4.2396368980407715]\n",
            "ppl: [66.27860906351756, 69.3826542866838]\n",
            "lp: [-134.20375061035156, -131.42874383926392]\n",
            "div_lp: [-0.5411392037401608, -0.5365264933659271]\n",
            "penalty: [-575.1816631402279, -551.0758222857645]\n",
            "slor: [3.5562037134171103, 3.662371577706973]\n",
            "pen_slor: [-0.197847960256695, -0.20602159325008912] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 1   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 0   total number of examples: 1   percentage of correct answers: 0.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 0   total number of examples: 1   percentage of correct answers: 0.0 \n",
            "\n",
            "0\u0001Many comments are thoughful and insightful, and since the rest of the comments can be skipped easily, Comment sections have not failed\u0001Many comments are thoughful and insightful, but since the rest of the comments make the section unreadable, Comment sections have not failed\n",
            "\n",
            "scores: [-4.587782382965088, -4.705200672149658]\n",
            "ppl: [98.27624924604775, 110.52046110083965]\n",
            "lp: [-114.6945595741272, -122.33521747589111]\n",
            "div_lp: [-0.5764291529675943, -0.5820576492952451]\n",
            "penalty: [-415.64142156898663, -455.11364144521286]\n",
            "slor: [3.371187699214297, 3.378535840628262]\n",
            "pen_slor: [-0.20277019591121043, -0.1930109841959315] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 2   total number of examples: 2   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 0   total number of examples: 2   percentage of correct answers: 0.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 2   percentage of correct answers: 0.5 \n",
            "\n",
            "1\u0001People can choose not to use Google, and since all other search engines re-direct to google, Google is not a harmful monopoly\u0001People can choose not to use Google, but since other search engines do not re-direct to google, Google is not a harmful monopoly\n",
            "\n",
            "scores: [-3.874293804168701, -3.8765087127685547]\n",
            "ppl: [48.1486838822554, 48.25544700789367]\n",
            "lp: [-100.73163890838623, -104.66573524475098]\n",
            "div_lp: [-0.4847822354219327, -0.48296263874719]\n",
            "penalty: [-374.7436260647887, -399.39581596369936]\n",
            "slor: [4.117529165162446, 4.150010114493649]\n",
            "pen_slor: [-0.2856773293742824, -0.28054944146313404] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 2   total number of examples: 3   percentage of correct answers: 0.6666666666666666 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 1   total number of examples: 3   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 1   total number of examples: 3   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "0\u0001Ginsberg is brave for speaking out, and since it does not show that she will be biased against anything that has anything to do with Trump, Supreme court justice can denounce a candidate\u0001Ginsberg is brave for speaking out, but since it shows she will be biased against anything that has anything to do with Trump, Supreme court justice can denounce a candidate\n",
            "\n",
            "scores: [-4.0310893058776855, -4.206762790679932]\n",
            "ppl: [56.322229979797896, 67.13884514338909]\n",
            "lp: [-149.15030431747437, -143.02993488311768]\n",
            "div_lp: [-0.5212233957881266, -0.5317664249033502]\n",
            "penalty: [-707.4611175976645, -639.3779078935654]\n",
            "slor: [3.7028100901430814, 3.704159361737871]\n",
            "pen_slor: [-0.19365583482597643, -0.19697492944978726] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 3   total number of examples: 4   percentage of correct answers: 0.75 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 1   total number of examples: 4   percentage of correct answers: 0.25 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 1   total number of examples: 4   percentage of correct answers: 0.25 \n",
            "\n",
            "1\u0001Attending the Olympics will risk the health of participants and fans as well as their families and entire countries, and since a huge pandemic would be a great news story, Brazil should postpone Olympics\u0001Attending the Olympics will risk the health of participants and fans as well as their families and entire countries, but since a huge pandemic would not be a great news story, Brazil should postpone Olympics\n",
            "\n",
            "scores: [-4.132857322692871, -4.097214221954346]\n",
            "ppl: [62.35583938626823, 60.17242686882866]\n",
            "lp: [-157.0485782623291, -159.79135465621948]\n",
            "div_lp: [-0.5129237635191145, -0.5078277263226152]\n",
            "penalty: [-759.0803921859186, -786.6733165803449]\n",
            "slor: [3.9245921788427647, 3.9709041764322923]\n",
            "pen_slor: [-0.1964673364392452, -0.196860958185357] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 5   percentage of correct answers: 0.8 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 2   total number of examples: 5   percentage of correct answers: 0.4 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 2   total number of examples: 5   percentage of correct answers: 0.4 \n",
            "\n",
            "1\u0001The justice is using her role as a citizen not a judge to speak and Trump is an enemy of law, and since the role of a citizen and a supreme court justice are inseparable, Supreme court justice can denounce a candidate\u0001The justice is using her role as a citizen not a judge to speak and Trump is an enemy of law, but since the role of a citizen and a supreme court justice are separable, Supreme court justice can denounce a candidate\n",
            "\n",
            "scores: [-4.032500743865967, -4.073163986206055]\n",
            "ppl: [56.40178144254779, 58.742529424444676]\n",
            "lp: [-181.4625334739685, -183.29237937927246]\n",
            "div_lp: [-0.5291450437281857, -0.5312724782350932]\n",
            "penalty: [-989.5596381435136, -999.5382360239996]\n",
            "slor: [3.5882845052110435, 3.5936438253659957]\n",
            "pen_slor: [-0.1631764236437854, -0.1617886803257689] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 4   total number of examples: 6   percentage of correct answers: 0.6666666666666666 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 3   total number of examples: 6   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 2   total number of examples: 6   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "0\u0001The reading public can use comments sections to voice their opinion on media, and since a majority of these comments are not trolls or arguments about preferences., Comment sections have not failed\u0001The reading public can use comments sections to voice their opinion on media, but since a majority of these comments are trolls or arguments about preferences., Comment sections have not failed\n",
            "\n",
            "scores: [-4.5024943351745605, -4.553386688232422]\n",
            "ppl: [90.241944460564, 94.95344209238259]\n",
            "lp: [-153.08480739593506, -150.26176071166992]\n",
            "div_lp: [-0.5495045264907193, -0.5477713810952312]\n",
            "penalty: [-684.3255851517232, -657.8916137666746]\n",
            "slor: [3.6912404169823976, 3.7591810094962153]\n",
            "pen_slor: [-0.18339541425968484, -0.188561414551442] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 7   percentage of correct answers: 0.7142857142857143 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 7   percentage of correct answers: 0.42857142857142855 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 2   total number of examples: 7   percentage of correct answers: 0.2857142857142857 \n",
            "\n",
            "1\u0001I find the idea that it is a sin to be born or live a life at all to be preposterous, and since being gay isn't considered a sin, Christians have created a harmful atmosphere for gays\u0001I find the idea that it is a sin to be born or live a life at all to be preposterous, but since being gay is considered a sin, Christians have created a harmful atmosphere for gays\n",
            "\n",
            "scores: [-3.1236488819122314, -3.1200666427612305]\n",
            "ppl: [22.729164552559958, 22.64788891073701]\n",
            "lp: [-131.19325304031372, -127.92273235321045]\n",
            "div_lp: [-0.4059079918373317, -0.40731873217448805]\n",
            "penalty: [-680.8771927422906, -652.5788468401947]\n",
            "slor: [4.571811529628615, 4.539946011468111]\n",
            "pen_slor: [-0.2820128009737568, -0.28523417112196786] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 6   total number of examples: 8   percentage of correct answers: 0.75 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 3   total number of examples: 8   percentage of correct answers: 0.375 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 3   total number of examples: 8   percentage of correct answers: 0.375 \n",
            "\n",
            "0\u0001Comments sections permit a reader to analyze many different perspectives in one place, and since I want to see all these ideas, even stupid ones, Comment sections have not failed\u0001Comments sections permit a reader to analyze many different perspectives in one place, but since I don't want to see all these stupid ideas, Comment sections have not failed\n",
            "\n",
            "scores: [-4.495534420013428, -4.479275226593018]\n",
            "ppl: [89.61604880004326, 88.17074570040657]\n",
            "lp: [-148.35263586044312, -143.33680725097656]\n",
            "div_lp: [-0.5511204008862445, -0.5403541424468669]\n",
            "penalty: [-649.5328854827319, -614.3248814498315]\n",
            "slor: [3.6615477942981065, 3.81024247065211]\n",
            "pen_slor: [-0.18602765142835845, -0.1984743948073747] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 6   total number of examples: 9   percentage of correct answers: 0.6666666666666666 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 9   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 9   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "1\u0001Comment sections provide insight, and since they can cause explosive meaningless arguments, Comment sections have not failed\u0001Comment sections provide insight, but since they can cause quiet meaningful debates, Comment sections have not failed\n",
            "\n",
            "scores: [-6.056812286376953, -5.999935626983643]\n",
            "ppl: [427.0120728050036, 403.40282440027596]\n",
            "lp: [-115.07943344116211, -113.99877691268921]\n",
            "div_lp: [-0.6706893609611291, -0.6607071905794861]\n",
            "penalty: [-348.85560746280026, -345.5796694569723]\n",
            "slor: [2.9739143643295076, 3.081145542605691]\n",
            "pen_slor: [-0.16197065981886477, -0.1694016473871218] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 7   total number of examples: 10   percentage of correct answers: 0.7 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 10   percentage of correct answers: 0.4 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 10   percentage of correct answers: 0.4 \n",
            "\n",
            "0\u0001There should be seating standards, and baggage fees should be waived for those in TSA line over 45 minutes, and since these standards are government's responsibility, Government should regulate airline industry again\u0001There should be seating standards, and baggage fees should be waived for those in TSA line over 45 minutes, but since these standards are not government's responsibility, Government should regulate airline industry again\n",
            "\n",
            "scores: [-4.760782718658447, -4.699642181396484]\n",
            "ppl: [116.83734088492923, 109.90783834607332]\n",
            "lp: [-171.3881778717041, -173.88676071166992]\n",
            "div_lp: [-0.5627488680912907, -0.5554974918506306]\n",
            "penalty: [-797.4196744194761, -824.7929672785987]\n",
            "slor: [3.6990880844688547, 3.7605979643145346]\n",
            "pen_slor: [-0.1669975990219013, -0.16869945574188963] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 7   total number of examples: 11   percentage of correct answers: 0.6363636363636364 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 4   total number of examples: 11   percentage of correct answers: 0.36363636363636365 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 4   total number of examples: 11   percentage of correct answers: 0.36363636363636365 \n",
            "\n",
            "1\u0001Pot hasn't led me to lose control, and since some people can't control their addiction, Marijuana is not a gateway drug\u0001Pot hasn't led me to lose control, but since most people can control their addiction, Marijuana is not a gateway drug\n",
            "\n",
            "scores: [-4.057003974914551, -4.256907939910889]\n",
            "ppl: [57.80087852252988, 70.59137288321284]\n",
            "lp: [-101.42509937286377, -102.16579055786133]\n",
            "div_lp: [-0.5050509900002862, -0.5219049129938794]\n",
            "penalty: [-367.5542470597053, -360.33205451870083]\n",
            "slor: [3.9758561822593843, 3.8995738902588357]\n",
            "pen_slor: [-0.2704264890192895, -0.25973202270672496] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 7   total number of examples: 12   percentage of correct answers: 0.5833333333333334 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 4   total number of examples: 12   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 4   total number of examples: 12   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "0\u0001It is good to be informed about your health, and since you are able to find information online, Medical websites are healthful\u0001It is good to be informed about your health, but since you aren't able to be diagnosed online, Medical websites are healthful\n",
            "\n",
            "scores: [-3.7779500484466553, -4.11328649520874]\n",
            "ppl: [43.72631297398608, 61.147348170071695]\n",
            "lp: [-94.44875121116638, -106.94544887542725]\n",
            "div_lp: [-0.5055072683149792, -0.5325083416803014]\n",
            "penalty: [-342.2726706880376, -397.8603518915598]\n",
            "slor: [3.695632005160204, 3.611074182840897]\n",
            "pen_slor: [-0.26993332521489616, -0.23598211861898033] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 8   total number of examples: 13   percentage of correct answers: 0.6153846153846154 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 13   percentage of correct answers: 0.38461538461538464 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 13   percentage of correct answers: 0.38461538461538464 \n",
            "\n",
            "1\u0001Comments are informative, and since Information isn't that important., Comment sections have not failed\u0001Comments are informative, but since Information is important., Comment sections have not failed\n",
            "\n",
            "scores: [-5.932198524475098, -6.164063453674316]\n",
            "ppl: [376.9824084696515, 475.3557417251875]\n",
            "lp: [-100.84737491607666, -92.46095180511475]\n",
            "div_lp: [-0.6857025897988378, -0.6968052645666797]\n",
            "penalty: [-285.1554932325174, -242.2486447200694]\n",
            "slor: [2.7190718844866155, 2.6821146209238216]\n",
            "pen_slor: [-0.16210181158453424, -0.1660761378473226] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 14   percentage of correct answers: 0.5714285714285714 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 5   total number of examples: 14   percentage of correct answers: 0.35714285714285715 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 6   total number of examples: 14   percentage of correct answers: 0.42857142857142855 \n",
            "\n",
            "1\u0001Comments sections permit a reader to analyze many different perspectives in one place, and since readers don't need multiple perspectives, Comment sections have not failed\u0001Comments sections permit a reader to analyze many different perspectives in one place, but since readers need multiple perspectives, Comment sections have not failed\n",
            "\n",
            "scores: [-4.448462963104248, -4.630211353302002]\n",
            "ppl: [85.49543332427176, 102.53573308626899]\n",
            "lp: [-124.55696296691895, -120.38549518585205]\n",
            "div_lp: [-0.5145811204590262, -0.526279520264353]\n",
            "penalty: [-487.14490203031664, -447.86025007079974]\n",
            "slor: [4.196360537485996, 4.167796501870137]\n",
            "pen_slor: [-0.24119742310737677, -0.24195652333845902] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 15   percentage of correct answers: 0.5333333333333333 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 5   total number of examples: 15   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 7   total number of examples: 15   percentage of correct answers: 0.4666666666666667 \n",
            "\n",
            "1\u0001Concealed carry permit holders have already been background checked and vetted for both character and competence, and since the majority of gun violence in performed by people who have already been background checked and vetted, Guns should be permitted on college campuses\u0001Concealed carry permit holders have already been background checked and vetted for both character and competence, but since the majority of gun violence in performed by people who have not already been background checked and vetted, Guns should be permitted on college campuses\n",
            "\n",
            "scores: [-3.705134868621826, -3.7285988330841064]\n",
            "ppl: [40.65553010245713, 41.62074967112844]\n",
            "lp: [-170.436203956604, -175.244145154953]\n",
            "div_lp: [-0.4336405946160247, -0.43646362307482817]\n",
            "penalty: [-944.2717421413226, -986.1096115340554]\n",
            "slor: [4.839117940326118, 4.814149373093131]\n",
            "pen_slor: [-0.23573661618869723, -0.22945220073799383] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 16   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 5   total number of examples: 16   percentage of correct answers: 0.3125 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 7   total number of examples: 16   percentage of correct answers: 0.4375 \n",
            "\n",
            "1\u0001Those that have committed crimes against society should have that seen when competing fairly for jobs with those who did not commit crimes, and since one punishment is enough, Jail record should be an employer's first impression\u0001Those that have committed crimes against society should have that seen when competing fairly for jobs with those who did not commit crimes, but since one punishment is not enough, Jail record should be an employer's first impression\n",
            "\n",
            "scores: [-4.621162414550781, -4.511364936828613]\n",
            "ppl: [101.61207886564017, 91.04600578374988]\n",
            "lp: [-184.84649658203125, -184.96596240997314]\n",
            "div_lp: [-0.5697822081274212, -0.5556375649548702]\n",
            "penalty: [-926.5315971071623, -943.5764248758072]\n",
            "slor: [3.4892389785326343, 3.6078934095631285]\n",
            "pen_slor: [-0.15063658873272384, -0.15676910305549213] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 9   total number of examples: 17   percentage of correct answers: 0.5294117647058824 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 6   total number of examples: 17   percentage of correct answers: 0.35294117647058826 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 8   total number of examples: 17   percentage of correct answers: 0.47058823529411764 \n",
            "\n",
            "1\u0001In America differing opinions are not only allowed but they have value teaching us to compromise for the best results, and since most often these opinions cannot be shared without entering into an ugly and unhealthy debate, Comment sections have not failed\u0001In America differing opinions are not only allowed but they have value teaching us to compromise for the best results, but since most often these opinions can be shared without entering into an ugly and unhealthy debate, Comment sections have not failed\n",
            "\n",
            "scores: [-4.491304397583008, -4.53260612487793]\n",
            "ppl: [89.23777152821144, 93.00061675243973]\n",
            "lp: [-197.61739349365234, -199.4346694946289]\n",
            "div_lp: [-0.5428142631133835, -0.5488397543660366]\n",
            "penalty: [-1060.3787857272182, -1070.1299563361383]\n",
            "slor: [3.782804635260994, 3.7259175859518945]\n",
            "pen_slor: [-0.1569659881844347, -0.1531966961687297] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 9   total number of examples: 18   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 6   total number of examples: 18   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 18   percentage of correct answers: 0.4444444444444444 \n",
            "\n",
            "0\u0001Justices are not prohibited from speaking about topics of interest to them, and since they are interested in the electoral process, Supreme court justice can denounce a candidate\u0001Justices are not prohibited from speaking about topics of interest to them, but since they should not be interested in the electoral process, Supreme court justice can denounce a candidate\n",
            "\n",
            "scores: [-3.848433256149292, -3.840989112854004]\n",
            "ppl: [46.91949478523968, 46.57151615106674]\n",
            "lp: [-119.30143094062805, -126.75264072418213]\n",
            "div_lp: [-0.4871125504980386, -0.4851017552097192]\n",
            "penalty: [-500.2264514973939, -554.961548169476]\n",
            "slor: [4.052067874882002, 4.076914855960678]\n",
            "pen_slor: [-0.2511144777436794, -0.24242794963087538] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 9   total number of examples: 19   percentage of correct answers: 0.47368421052631576 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 6   total number of examples: 19   percentage of correct answers: 0.3157894736842105 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 9   total number of examples: 19   percentage of correct answers: 0.47368421052631576 \n",
            "\n",
            "0\u0001The Olympics are a dream for many athletes since they train extremely hard, and since the athletes won't get sick going to Brazil, Brazil should not postpone Olympics\u0001The Olympics are a dream for many athletes since they train extremely hard, but since the athletes won't be able to compete if they are sick, Brazil should not postpone Olympics\n",
            "\n",
            "scores: [-4.18632698059082, -3.5245521068573]\n",
            "ppl: [65.78073278209297, 33.93856935907147]\n",
            "lp: [-129.77613639831543, -119.8347716331482]\n",
            "div_lp: [-0.5104539188932842, -0.4350139300333714]\n",
            "penalty: [-544.1465009072535, -535.6899983371884]\n",
            "slor: [4.014857936682811, 4.577607073624391]\n",
            "pen_slor: [-0.22872626366181617, -0.29053863425925497] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 9   total number of examples: 20   percentage of correct answers: 0.45 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 6   total number of examples: 20   percentage of correct answers: 0.3 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 9   total number of examples: 20   percentage of correct answers: 0.45 \n",
            "\n",
            " percentage of correct answers ppl: 0.4572072072072072\n",
            " percentage of correct answers slor: 0.5\n",
            " percentage of correct answers pen_slor: 0.5022522522522522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0We3bEBfXY2_",
        "outputId": "6a7f8e2a-157a-44d8-e4e8-a13f626220ed"
      },
      "source": [
        "test = 'arct_2'\r\n",
        "show_results()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\u0001They add a lot to the piece and I look forward to reading comments, and since comments sections are a welcome distraction from my work, Comment sections have not failed\u0001They add a lot to the piece and I look forward to reading comments, but since comments sections always distract me from my work, Comment sections have not failed\n",
            "\n",
            "scores: [-4.193867206573486, -4.2396368980407715]\n",
            "ppl: [66.27860906351756, 69.3826542866838]\n",
            "lp: [-134.20375061035156, -131.42874383926392]\n",
            "div_lp: [-0.5411392037401608, -0.5365264933659271]\n",
            "penalty: [-575.1816631402279, -551.0758222857645]\n",
            "slor: [3.5562037134171103, 3.662371577706973]\n",
            "pen_slor: [-0.197847960256695, -0.20602159325008912] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 1   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 0   total number of examples: 1   percentage of correct answers: 0.0 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 0   total number of examples: 1   percentage of correct answers: 0.0 \n",
            "\n",
            "0\u0001Many comments are thoughful and insightful, and since the rest of the comments can be skipped easily, Comment sections have not failed\u0001Many comments are thoughful and insightful, but since the rest of the comments make the section unreadable, Comment sections have not failed\n",
            "\n",
            "scores: [-4.587782382965088, -4.705200672149658]\n",
            "ppl: [98.27624924604775, 110.52046110083965]\n",
            "lp: [-114.6945595741272, -122.33521747589111]\n",
            "div_lp: [-0.5764291529675943, -0.5820576492952451]\n",
            "penalty: [-415.64142156898663, -455.11364144521286]\n",
            "slor: [3.371187699214297, 3.378535840628262]\n",
            "pen_slor: [-0.20277019591121043, -0.1930109841959315] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 2   total number of examples: 2   percentage of correct answers: 1.0 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 0   total number of examples: 2   percentage of correct answers: 0.0 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 1   total number of examples: 2   percentage of correct answers: 0.5 \n",
            "\n",
            "1\u0001People can choose not to use Google, and since all other search engines re-direct to google, Google is not a harmful monopoly\u0001People can choose not to use Google, but since other search engines do not re-direct to google, Google is not a harmful monopoly\n",
            "\n",
            "scores: [-3.874293804168701, -3.8765087127685547]\n",
            "ppl: [48.1486838822554, 48.25544700789367]\n",
            "lp: [-100.73163890838623, -104.66573524475098]\n",
            "div_lp: [-0.4847822354219327, -0.48296263874719]\n",
            "penalty: [-374.7436260647887, -399.39581596369936]\n",
            "slor: [4.117529165162446, 4.150010114493649]\n",
            "pen_slor: [-0.2856773293742824, -0.28054944146313404] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 2   total number of examples: 3   percentage of correct answers: 0.6666666666666666 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 1   total number of examples: 3   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 1   total number of examples: 3   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "0\u0001Ginsberg is brave for speaking out, and since it does not show that she will be biased against anything that has anything to do with Trump, Supreme court justice can denounce a candidate\u0001Ginsberg is brave for speaking out, but since it shows she will be biased against anything that has anything to do with Trump, Supreme court justice can denounce a candidate\n",
            "\n",
            "scores: [-4.0310893058776855, -4.206762790679932]\n",
            "ppl: [56.322229979797896, 67.13884514338909]\n",
            "lp: [-149.15030431747437, -143.02993488311768]\n",
            "div_lp: [-0.5212233957881266, -0.5317664249033502]\n",
            "penalty: [-707.4611175976645, -639.3779078935654]\n",
            "slor: [3.7028100901430814, 3.704159361737871]\n",
            "pen_slor: [-0.19365583482597643, -0.19697492944978726] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 3   total number of examples: 4   percentage of correct answers: 0.75 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 1   total number of examples: 4   percentage of correct answers: 0.25 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 1   total number of examples: 4   percentage of correct answers: 0.25 \n",
            "\n",
            "1\u0001Attending the Olympics will risk the health of participants and fans as well as their families and entire countries, and since a huge pandemic would be a great news story, Brazil should postpone Olympics\u0001Attending the Olympics will risk the health of participants and fans as well as their families and entire countries, but since a huge pandemic would not be a great news story, Brazil should postpone Olympics\n",
            "\n",
            "scores: [-4.132857322692871, -4.097214221954346]\n",
            "ppl: [62.35583938626823, 60.17242686882866]\n",
            "lp: [-157.0485782623291, -159.79135465621948]\n",
            "div_lp: [-0.5129237635191145, -0.5078277263226152]\n",
            "penalty: [-759.0803921859186, -786.6733165803449]\n",
            "slor: [3.9245921788427647, 3.9709041764322923]\n",
            "pen_slor: [-0.1964673364392452, -0.196860958185357] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 5   percentage of correct answers: 0.8 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 2   total number of examples: 5   percentage of correct answers: 0.4 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 2   total number of examples: 5   percentage of correct answers: 0.4 \n",
            "\n",
            "1\u0001The justice is using her role as a citizen not a judge to speak and Trump is an enemy of law, and since the role of a citizen and a supreme court justice are inseparable, Supreme court justice can denounce a candidate\u0001The justice is using her role as a citizen not a judge to speak and Trump is an enemy of law, but since the role of a citizen and a supreme court justice are separable, Supreme court justice can denounce a candidate\n",
            "\n",
            "scores: [-4.032500743865967, -4.073163986206055]\n",
            "ppl: [56.40178144254779, 58.742529424444676]\n",
            "lp: [-181.4625334739685, -183.29237937927246]\n",
            "div_lp: [-0.5291450437281857, -0.5312724782350932]\n",
            "penalty: [-989.5596381435136, -999.5382360239996]\n",
            "slor: [3.5882845052110435, 3.5936438253659957]\n",
            "pen_slor: [-0.1631764236437854, -0.1617886803257689] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 4   total number of examples: 6   percentage of correct answers: 0.6666666666666666 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 3   total number of examples: 6   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 2   total number of examples: 6   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "0\u0001The reading public can use comments sections to voice their opinion on media, and since a majority of these comments are not trolls or arguments about preferences., Comment sections have not failed\u0001The reading public can use comments sections to voice their opinion on media, but since a majority of these comments are trolls or arguments about preferences., Comment sections have not failed\n",
            "\n",
            "scores: [-4.5024943351745605, -4.553386688232422]\n",
            "ppl: [90.241944460564, 94.95344209238259]\n",
            "lp: [-153.08480739593506, -150.26176071166992]\n",
            "div_lp: [-0.5495045264907193, -0.5477713810952312]\n",
            "penalty: [-684.3255851517232, -657.8916137666746]\n",
            "slor: [3.6912404169823976, 3.7591810094962153]\n",
            "pen_slor: [-0.18339541425968484, -0.188561414551442] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 7   percentage of correct answers: 0.7142857142857143 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 7   percentage of correct answers: 0.42857142857142855 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 2   total number of examples: 7   percentage of correct answers: 0.2857142857142857 \n",
            "\n",
            "1\u0001I find the idea that it is a sin to be born or live a life at all to be preposterous, and since being gay isn't considered a sin, Christians have created a harmful atmosphere for gays\u0001I find the idea that it is a sin to be born or live a life at all to be preposterous, but since being gay is considered a sin, Christians have created a harmful atmosphere for gays\n",
            "\n",
            "scores: [-3.1236488819122314, -3.1200666427612305]\n",
            "ppl: [22.729164552559958, 22.64788891073701]\n",
            "lp: [-131.19325304031372, -127.92273235321045]\n",
            "div_lp: [-0.4059079918373317, -0.40731873217448805]\n",
            "penalty: [-680.8771927422906, -652.5788468401947]\n",
            "slor: [4.571811529628615, 4.539946011468111]\n",
            "pen_slor: [-0.2820128009737568, -0.28523417112196786] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 6   total number of examples: 8   percentage of correct answers: 0.75 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 3   total number of examples: 8   percentage of correct answers: 0.375 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 3   total number of examples: 8   percentage of correct answers: 0.375 \n",
            "\n",
            "0\u0001Comments sections permit a reader to analyze many different perspectives in one place, and since I want to see all these ideas, even stupid ones, Comment sections have not failed\u0001Comments sections permit a reader to analyze many different perspectives in one place, but since I don't want to see all these stupid ideas, Comment sections have not failed\n",
            "\n",
            "scores: [-4.495534420013428, -4.479275226593018]\n",
            "ppl: [89.61604880004326, 88.17074570040657]\n",
            "lp: [-148.35263586044312, -143.33680725097656]\n",
            "div_lp: [-0.5511204008862445, -0.5403541424468669]\n",
            "penalty: [-649.5328854827319, -614.3248814498315]\n",
            "slor: [3.6615477942981065, 3.81024247065211]\n",
            "pen_slor: [-0.18602765142835845, -0.1984743948073747] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 6   total number of examples: 9   percentage of correct answers: 0.6666666666666666 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 9   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 3   total number of examples: 9   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "1\u0001Comment sections provide insight, and since they can cause explosive meaningless arguments, Comment sections have not failed\u0001Comment sections provide insight, but since they can cause quiet meaningful debates, Comment sections have not failed\n",
            "\n",
            "scores: [-6.056812286376953, -5.999935626983643]\n",
            "ppl: [427.0120728050036, 403.40282440027596]\n",
            "lp: [-115.07943344116211, -113.99877691268921]\n",
            "div_lp: [-0.6706893609611291, -0.6607071905794861]\n",
            "penalty: [-348.85560746280026, -345.5796694569723]\n",
            "slor: [2.9739143643295076, 3.081145542605691]\n",
            "pen_slor: [-0.16197065981886477, -0.1694016473871218] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 7   total number of examples: 10   percentage of correct answers: 0.7 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 10   percentage of correct answers: 0.4 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 4   total number of examples: 10   percentage of correct answers: 0.4 \n",
            "\n",
            "0\u0001There should be seating standards, and baggage fees should be waived for those in TSA line over 45 minutes, and since these standards are government's responsibility, Government should regulate airline industry again\u0001There should be seating standards, and baggage fees should be waived for those in TSA line over 45 minutes, but since these standards are not government's responsibility, Government should regulate airline industry again\n",
            "\n",
            "scores: [-4.760782718658447, -4.699642181396484]\n",
            "ppl: [116.83734088492923, 109.90783834607332]\n",
            "lp: [-171.3881778717041, -173.88676071166992]\n",
            "div_lp: [-0.5627488680912907, -0.5554974918506306]\n",
            "penalty: [-797.4196744194761, -824.7929672785987]\n",
            "slor: [3.6990880844688547, 3.7605979643145346]\n",
            "pen_slor: [-0.1669975990219013, -0.16869945574188963] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 7   total number of examples: 11   percentage of correct answers: 0.6363636363636364 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 4   total number of examples: 11   percentage of correct answers: 0.36363636363636365 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 4   total number of examples: 11   percentage of correct answers: 0.36363636363636365 \n",
            "\n",
            "1\u0001Pot hasn't led me to lose control, and since some people can't control their addiction, Marijuana is not a gateway drug\u0001Pot hasn't led me to lose control, but since most people can control their addiction, Marijuana is not a gateway drug\n",
            "\n",
            "scores: [-4.057003974914551, -4.256907939910889]\n",
            "ppl: [57.80087852252988, 70.59137288321284]\n",
            "lp: [-101.42509937286377, -102.16579055786133]\n",
            "div_lp: [-0.5050509900002862, -0.5219049129938794]\n",
            "penalty: [-367.5542470597053, -360.33205451870083]\n",
            "slor: [3.9758561822593843, 3.8995738902588357]\n",
            "pen_slor: [-0.2704264890192895, -0.25973202270672496] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 7   total number of examples: 12   percentage of correct answers: 0.5833333333333334 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 4   total number of examples: 12   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 4   total number of examples: 12   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "0\u0001It is good to be informed about your health, and since you are able to find information online, Medical websites are healthful\u0001It is good to be informed about your health, but since you aren't able to be diagnosed online, Medical websites are healthful\n",
            "\n",
            "scores: [-3.7779500484466553, -4.11328649520874]\n",
            "ppl: [43.72631297398608, 61.147348170071695]\n",
            "lp: [-94.44875121116638, -106.94544887542725]\n",
            "div_lp: [-0.5055072683149792, -0.5325083416803014]\n",
            "penalty: [-342.2726706880376, -397.8603518915598]\n",
            "slor: [3.695632005160204, 3.611074182840897]\n",
            "pen_slor: [-0.26993332521489616, -0.23598211861898033] \n",
            "\n",
            "predicted label ppl: 0   correct label: 0\n",
            "correct answers: 8   total number of examples: 13   percentage of correct answers: 0.6153846153846154 \n",
            "\n",
            "predicted label slor: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 13   percentage of correct answers: 0.38461538461538464 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 5   total number of examples: 13   percentage of correct answers: 0.38461538461538464 \n",
            "\n",
            "1\u0001Comments are informative, and since Information isn't that important., Comment sections have not failed\u0001Comments are informative, but since Information is important., Comment sections have not failed\n",
            "\n",
            "scores: [-5.932198524475098, -6.164063453674316]\n",
            "ppl: [376.9824084696515, 475.3557417251875]\n",
            "lp: [-100.84737491607666, -92.46095180511475]\n",
            "div_lp: [-0.6857025897988378, -0.6968052645666797]\n",
            "penalty: [-285.1554932325174, -242.2486447200694]\n",
            "slor: [2.7190718844866155, 2.6821146209238216]\n",
            "pen_slor: [-0.16210181158453424, -0.1660761378473226] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 14   percentage of correct answers: 0.5714285714285714 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 5   total number of examples: 14   percentage of correct answers: 0.35714285714285715 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 6   total number of examples: 14   percentage of correct answers: 0.42857142857142855 \n",
            "\n",
            "1\u0001Comments sections permit a reader to analyze many different perspectives in one place, and since readers don't need multiple perspectives, Comment sections have not failed\u0001Comments sections permit a reader to analyze many different perspectives in one place, but since readers need multiple perspectives, Comment sections have not failed\n",
            "\n",
            "scores: [-4.448462963104248, -4.630211353302002]\n",
            "ppl: [85.49543332427176, 102.53573308626899]\n",
            "lp: [-124.55696296691895, -120.38549518585205]\n",
            "div_lp: [-0.5145811204590262, -0.526279520264353]\n",
            "penalty: [-487.14490203031664, -447.86025007079974]\n",
            "slor: [4.196360537485996, 4.167796501870137]\n",
            "pen_slor: [-0.24119742310737677, -0.24195652333845902] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 15   percentage of correct answers: 0.5333333333333333 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 5   total number of examples: 15   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 7   total number of examples: 15   percentage of correct answers: 0.4666666666666667 \n",
            "\n",
            "1\u0001Concealed carry permit holders have already been background checked and vetted for both character and competence, and since the majority of gun violence in performed by people who have already been background checked and vetted, Guns should be permitted on college campuses\u0001Concealed carry permit holders have already been background checked and vetted for both character and competence, but since the majority of gun violence in performed by people who have not already been background checked and vetted, Guns should be permitted on college campuses\n",
            "\n",
            "scores: [-3.705134868621826, -3.7285988330841064]\n",
            "ppl: [40.65553010245713, 41.62074967112844]\n",
            "lp: [-170.436203956604, -175.244145154953]\n",
            "div_lp: [-0.4336405946160247, -0.43646362307482817]\n",
            "penalty: [-944.2717421413226, -986.1096115340554]\n",
            "slor: [4.839117940326118, 4.814149373093131]\n",
            "pen_slor: [-0.23573661618869723, -0.22945220073799383] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 16   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 5   total number of examples: 16   percentage of correct answers: 0.3125 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 7   total number of examples: 16   percentage of correct answers: 0.4375 \n",
            "\n",
            "1\u0001Those that have committed crimes against society should have that seen when competing fairly for jobs with those who did not commit crimes, and since one punishment is enough, Jail record should be an employer's first impression\u0001Those that have committed crimes against society should have that seen when competing fairly for jobs with those who did not commit crimes, but since one punishment is not enough, Jail record should be an employer's first impression\n",
            "\n",
            "scores: [-4.621162414550781, -4.511364936828613]\n",
            "ppl: [101.61207886564017, 91.04600578374988]\n",
            "lp: [-184.84649658203125, -184.96596240997314]\n",
            "div_lp: [-0.5697822081274212, -0.5556375649548702]\n",
            "penalty: [-926.5315971071623, -943.5764248758072]\n",
            "slor: [3.4892389785326343, 3.6078934095631285]\n",
            "pen_slor: [-0.15063658873272384, -0.15676910305549213] \n",
            "\n",
            "predicted label ppl: 1   correct label: 1\n",
            "correct answers: 9   total number of examples: 17   percentage of correct answers: 0.5294117647058824 \n",
            "\n",
            "predicted label slor: 1   correct label: 1\n",
            "correct answers: 6   total number of examples: 17   percentage of correct answers: 0.35294117647058826 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 1\n",
            "correct answers: 8   total number of examples: 17   percentage of correct answers: 0.47058823529411764 \n",
            "\n",
            "1\u0001In America differing opinions are not only allowed but they have value teaching us to compromise for the best results, and since most often these opinions cannot be shared without entering into an ugly and unhealthy debate, Comment sections have not failed\u0001In America differing opinions are not only allowed but they have value teaching us to compromise for the best results, but since most often these opinions can be shared without entering into an ugly and unhealthy debate, Comment sections have not failed\n",
            "\n",
            "scores: [-4.491304397583008, -4.53260612487793]\n",
            "ppl: [89.23777152821144, 93.00061675243973]\n",
            "lp: [-197.61739349365234, -199.4346694946289]\n",
            "div_lp: [-0.5428142631133835, -0.5488397543660366]\n",
            "penalty: [-1060.3787857272182, -1070.1299563361383]\n",
            "slor: [3.782804635260994, 3.7259175859518945]\n",
            "pen_slor: [-0.1569659881844347, -0.1531966961687297] \n",
            "\n",
            "predicted label ppl: 0   correct label: 1\n",
            "correct answers: 9   total number of examples: 18   percentage of correct answers: 0.5 \n",
            "\n",
            "predicted label slor: 0   correct label: 1\n",
            "correct answers: 6   total number of examples: 18   percentage of correct answers: 0.3333333333333333 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 1\n",
            "correct answers: 8   total number of examples: 18   percentage of correct answers: 0.4444444444444444 \n",
            "\n",
            "0\u0001Justices are not prohibited from speaking about topics of interest to them, and since they are interested in the electoral process, Supreme court justice can denounce a candidate\u0001Justices are not prohibited from speaking about topics of interest to them, but since they should not be interested in the electoral process, Supreme court justice can denounce a candidate\n",
            "\n",
            "scores: [-3.848433256149292, -3.840989112854004]\n",
            "ppl: [46.91949478523968, 46.57151615106674]\n",
            "lp: [-119.30143094062805, -126.75264072418213]\n",
            "div_lp: [-0.4871125504980386, -0.4851017552097192]\n",
            "penalty: [-500.2264514973939, -554.961548169476]\n",
            "slor: [4.052067874882002, 4.076914855960678]\n",
            "pen_slor: [-0.2511144777436794, -0.24242794963087538] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 9   total number of examples: 19   percentage of correct answers: 0.47368421052631576 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 6   total number of examples: 19   percentage of correct answers: 0.3157894736842105 \n",
            "\n",
            "predicted label pen slor: 0   correct label: 0\n",
            "correct answers: 9   total number of examples: 19   percentage of correct answers: 0.47368421052631576 \n",
            "\n",
            "0\u0001The Olympics are a dream for many athletes since they train extremely hard, and since the athletes won't get sick going to Brazil, Brazil should not postpone Olympics\u0001The Olympics are a dream for many athletes since they train extremely hard, but since the athletes won't be able to compete if they are sick, Brazil should not postpone Olympics\n",
            "\n",
            "scores: [-4.18632698059082, -3.5245521068573]\n",
            "ppl: [65.78073278209297, 33.93856935907147]\n",
            "lp: [-129.77613639831543, -119.8347716331482]\n",
            "div_lp: [-0.5104539188932842, -0.4350139300333714]\n",
            "penalty: [-544.1465009072535, -535.6899983371884]\n",
            "slor: [4.014857936682811, 4.577607073624391]\n",
            "pen_slor: [-0.22872626366181617, -0.29053863425925497] \n",
            "\n",
            "predicted label ppl: 1   correct label: 0\n",
            "correct answers: 9   total number of examples: 20   percentage of correct answers: 0.45 \n",
            "\n",
            "predicted label slor: 1   correct label: 0\n",
            "correct answers: 6   total number of examples: 20   percentage of correct answers: 0.3 \n",
            "\n",
            "predicted label pen slor: 1   correct label: 0\n",
            "correct answers: 9   total number of examples: 20   percentage of correct answers: 0.45 \n",
            "\n",
            " percentage of correct answers ppl: 0.5292792792792793\n",
            " percentage of correct answers slor: 0.5315315315315315\n",
            " percentage of correct answers pen_slor: 0.5337837837837838\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}